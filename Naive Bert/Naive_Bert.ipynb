{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/13ErkLg5FZHIbnUGZRkKlL-9WNCNQPIow#scrollTo=H5t4_7HdjYEE\n",
        "\n",
        "\n",
        "1.   pip install transformers \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eymPZuLWWLXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pUryLC03KDgE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "max_sequence_length = 512\n",
        "learning_rate = 2e-5\n",
        "number_of_epochs = 1\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 6)\n",
        "# choosing Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTOLTxXF8R4P",
        "outputId": "89ce105f-3b9e-475d-f02f-de8478e0ee7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LbAc7SNmKDgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65ae7618-a17e-4953-be3b-0f95b47bab4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  \\\n",
              "0     0016926B079C  I think that students would benefit from learn...   \n",
              "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
              "2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
              "3     003885A45F42  The best time in life is when you become yours...   \n",
              "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
              "...            ...                                                ...   \n",
              "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
              "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
              "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
              "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
              "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
              "\n",
              "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0          3.5     3.5         3.0          3.0      4.0          3.0  \n",
              "1          2.5     2.5         3.0          2.0      2.0          2.5  \n",
              "2          3.0     3.5         3.0          3.0      3.0          2.5  \n",
              "3          4.5     4.5         4.5          4.5      4.0          5.0  \n",
              "4          2.5     3.0         3.0          3.0      2.5          2.5  \n",
              "...        ...     ...         ...          ...      ...          ...  \n",
              "3906       2.5     3.0         3.0          3.5      2.5          2.5  \n",
              "3907       4.0     4.0         4.0          4.0      3.5          3.0  \n",
              "3908       2.5     3.0         3.0          3.0      3.5          3.0  \n",
              "3909       4.0     4.5         4.5          4.0      4.5          4.5  \n",
              "3910       3.5     2.5         3.5          3.0      3.0          3.5  \n",
              "\n",
              "[3911 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62b57161-c159-4336-83ce-5769e0479c79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>FFD29828A873</td>\n",
              "      <td>I believe using cellphones in class for educat...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>FFD9A83B0849</td>\n",
              "      <td>Working alone, students do not have to argue w...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>FFDC4011AC9C</td>\n",
              "      <td>\"A problem is a chance for you to do your best...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>FFE16D704B16</td>\n",
              "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>FFED00D6E0BD</td>\n",
              "      <td>Do you think that failure is the main thing fo...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3911 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62b57161-c159-4336-83ce-5769e0479c79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62b57161-c159-4336-83ce-5769e0479c79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62b57161-c159-4336-83ce-5769e0479c79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ju6MBoa2KDgH"
      },
      "outputs": [],
      "source": [
        "def get_label(df):\n",
        "  df_cohesion = df[[\"text_id\", \"full_text\", \"cohesion\"]]\n",
        "  df_cohesion['rating'] = np.zeros(len(df_cohesion))\n",
        "  for i in range(1, len(df_cohesion)):\n",
        "    score = df_cohesion.loc[i, 'cohesion']\n",
        "    if score >= 3:\n",
        "        df_cohesion.loc[i, 'rating'] = 1\n",
        "    else:\n",
        "        df_cohesion.loc[i, 'rating'] = 0\n",
        "\n",
        "  return df_cohesion\n",
        "\n",
        "#df_cohesion = get_label(df)\n",
        "df_cohesion = df[['text_id', 'full_text', 'cohesion']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/how-to-apply-transformers-to-any-length-of-text-a5601410af7f"
      ],
      "metadata": {
        "id": "Zz5xFe9MuKWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, label\n",
        "\n",
        "def convert_example_to_feature(review): #make dataset to be a square \n",
        "  return tokenizer.encode_plus(review,\n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = 512, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens 按照最大长度补齐\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n",
        "  \n",
        "def encode_examples():  \n",
        "  max_len = 0\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []\n",
        "\n",
        "  sentences = df_cohesion[\"full_text\"].values\n",
        "  #labels_raw = df_cohesion[\"rating\"].values\n",
        "  labels_raw = df_cohesion[\"cohesion\"].values\n",
        "\n",
        "  for k in range(len(sentences)):\n",
        "      sent = sentences[k]\n",
        "      tokens = convert_example_to_feature(sent)\n",
        "      input_ids_list.append(tokens['input_ids'])\n",
        "      token_type_ids_list.append(tokens['token_type_ids'])\n",
        "      attention_mask_list.append(tokens['attention_mask'])\n",
        "      label_list.append([labels_raw[k]])\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, \n",
        "                                             token_type_ids_list, label_list)).map(map_example_to_dict)\n",
        "  return dataset\n",
        "\n",
        "ds_train_encoded = encode_examples().shuffle(1000).batch(batch_size)\n",
        "ds_test_encoded = encode_examples().shuffle(100).batch(batch_size)"
      ],
      "metadata": {
        "id": "u7YOhhWxr3U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8303938d-83e3-4f32-adc5-376785469f18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)"
      ],
      "metadata": {
        "id": "MVylP1WfdR-i",
        "outputId": "9263d4e1-b025-4600-8e75-0ef3301fb83c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652/652 [==============================] - 124s 157ms/step - loss: 0.9743 - accuracy: 0.2807 - val_loss: 0.7969 - val_accuracy: 0.3278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getLongestParagraph(df_cohesion):\n",
        "  lengths = df_cohesion[\"full_text\"].str.len()\n",
        "  argmax = np.where(lengths == lengths.max())[0]\n",
        "  return df_cohesion.iloc[argmax][\"full_text\"].values[0]\n",
        "\n",
        "def predict_grade(txt):\n",
        "  tokens = tokenizer.encode(txt, truncation=True, padding=True, return_tensors='tf')\n",
        "  tf_output= model.predict(tokens)[0]\n",
        "  tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
        "  numpy_prediction = tf_prediction.numpy()\n",
        "  txt_label = tf.argmax(numpy_prediction, axis=1)\n",
        "  return txt_label.numpy()[0]\n",
        "\n",
        "#txt = getLongestParagraph(df_cohesion)\n",
        "txt = df_cohesion[\"full_text\"][4]\n",
        "print(predict_grade(txt))"
      ],
      "metadata": {
        "id": "UWq51jcdEdk9",
        "outputId": "ceb38747-0b83-4f1c-a5de-d6cc41b0115a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getLongestParagraph(df_cohesion):\n",
        "  lengths = df_cohesion[\"full_text\"].str.len()\n",
        "  argmax = np.where(lengths == lengths.max())[0]\n",
        "  return df_cohesion.iloc[argmax][\"full_text\"].values[0]\n",
        "\n",
        "def getGrade(numpy_prediction):\n",
        "  return int(numpy_prediction[0][1]*10) / 2\n",
        "\n",
        "def predict_grade(txt):\n",
        "  tokens = tokenizer.encode(txt, truncation=True, padding=True, return_tensors='tf')\n",
        "  tf_output= model.predict(tokens)[0]\n",
        "  tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
        "  numpy_prediction = tf_prediction.numpy()\n",
        "  txt_grading = getGrade(numpy_prediction)\n",
        "  return txt_grading\n",
        "\n",
        "txt = getLongestParagraph(df_cohesion)\n",
        "predict_grade(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CtZLfSFO6le",
        "outputId": "6832c445-4c80-4555-d3c7-3f12166aac89"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def computeLoss100(df_cohesion, model):\n",
        "    loss = 0\n",
        "    for index, row in df_cohesion.head(100).iterrows():\n",
        "        txt = row[\"full_text\"]\n",
        "        predicted_cohesion_score = predict_grade(txt)\n",
        "        loss = loss + (row[\"cohesion\"] - predicted_cohesion_score) ** 2\n",
        "    return loss\n",
        "    \n",
        "loss = computeLoss100(df_cohesion, model)"
      ],
      "metadata": {
        "id": "uDD8iPV3VXWr",
        "outputId": "05955790-c30d-4c95-e125-182b2561c64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6e49457bab62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeLoss100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cohesion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-6e49457bab62>\u001b[0m in \u001b[0;36mcomputeLoss100\u001b[0;34m(df_cohesion, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpredicted_cohesion_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_grade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cohesion\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredicted_cohesion_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert 3.5 to EagerTensor of dtype int64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "pFk-4UzjW5nV",
        "outputId": "d5739169-a629-49ec-fd59-ab87a3cc3d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "213.0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def breakintochunks(input_id_chunks, mask_chunks, label): #Not useful by now\n",
        "    input_id_chunks_ = list(input_id_chunks)\n",
        "    mask_chunks_ = list(mask_chunks)\n",
        "\n",
        "    for i in range(len(input_id_chunks_)):\n",
        "      input_id_chunks_[i] = torch.cat([\n",
        "          torch.Tensor([101]), input_id_chunks_[i], torch.Tensor([102])\n",
        "          ])\n",
        "      mask_chunks_[i] = torch.cat([\n",
        "          torch.Tensor([1]), mask_chunks_[i], torch.Tensor([1])\n",
        "          ])\n",
        "      \n",
        "      pad_len = max_sequence_length - input_id_chunks_[i].shape[0]\n",
        "      if pad_len > 0:\n",
        "        input_id_chunks_[i] = torch.cat([\n",
        "            input_id_chunks_[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "\n",
        "        mask_chunks_[i] = torch.cat([\n",
        "            mask_chunks_[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "      #print(len(input_id_chunks_[i]), end = ' ')\n",
        "    #print()\n",
        "\n",
        "    input_id = torch.stack(input_id_chunks_)\n",
        "    attention_mask = torch.stack(mask_chunks_)\n",
        "    labels_nparray = np.full(len(input_id_chunks_), label)\n",
        "    labels_tensor = torch.from_numpy(labels_nparray)\n",
        "    #print(len(input_id), len(attention_mask), len(labels_tensor))\n",
        "    return input_id, attention_mask, labels_tensor"
      ],
      "metadata": {
        "id": "d6aFBD5cUfD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "fbb39bc871e7848362a0c6dcbdac16925c4e41c1ea31b4ffde16ac0c0ba5ae0b"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}