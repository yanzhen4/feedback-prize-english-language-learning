{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanzhen4/feedback-prize-english-language-learning/blob/master/fb3_deberta_v3_base_baseline_train2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4487dd87",
      "metadata": {
        "papermill": {
          "duration": 0.006995,
          "end_time": "2022-08-31T22:31:20.199821",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.192826",
          "status": "completed"
        },
        "tags": [],
        "id": "4487dd87"
      },
      "source": [
        "# About this notebook\n",
        "- Deberta-v3-base starter code\n",
        "- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/fb3-pip-wheels)\n",
        "- Inference notebook is [here](https://www.kaggle.com/yasufuminakama/fb3-deberta-v3-base-baseline-inference)\n",
        "\n",
        "If this notebook is helpful, feel free to upvote :)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip install wandb transformers tokenizers iterative-stratification"
      ],
      "metadata": {
        "id": "J5uY3toQO9es"
      },
      "id": "J5uY3toQO9es"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9f89e5f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.233612Z",
          "iopub.status.busy": "2022-08-31T22:31:20.233146Z",
          "iopub.status.idle": "2022-08-31T22:31:20.248183Z",
          "shell.execute_reply": "2022-08-31T22:31:20.247226Z"
        },
        "papermill": {
          "duration": 0.027843,
          "end_time": "2022-08-31T22:31:20.251266",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.223423",
          "status": "completed"
        },
        "tags": [],
        "id": "9f89e5f8"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = '/content/gdrive/MyDrive/Colab_Notebooks/Deberta/'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00af3d33",
      "metadata": {
        "papermill": {
          "duration": 0.006899,
          "end_time": "2022-08-31T22:31:20.215491",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.208592",
          "status": "completed"
        },
        "tags": [],
        "id": "00af3d33"
      },
      "source": [
        "# Directory settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvhPIWIZOA9T",
        "outputId": "68b1600e-2766-49be-e44b-cec524e2a7b9"
      },
      "id": "FvhPIWIZOA9T",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b42ab58",
      "metadata": {
        "papermill": {
          "duration": 0.00523,
          "end_time": "2022-08-31T22:31:20.262025",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.256795",
          "status": "completed"
        },
        "tags": [],
        "id": "8b42ab58"
      },
      "source": [
        "# CFG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5d62d96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.275246Z",
          "iopub.status.busy": "2022-08-31T22:31:20.274550Z",
          "iopub.status.idle": "2022-08-31T22:31:20.282480Z",
          "shell.execute_reply": "2022-08-31T22:31:20.281625Z"
        },
        "papermill": {
          "duration": 0.01687,
          "end_time": "2022-08-31T22:31:20.284537",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.267667",
          "status": "completed"
        },
        "tags": [],
        "id": "e5d62d96"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    wandb=True\n",
        "    competition='FB3'\n",
        "    _wandb_kernel='nakama'\n",
        "    debug=False\n",
        "    apex=True\n",
        "    print_freq=20\n",
        "    num_workers=4\n",
        "    model=\"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\"\n",
        "    gradient_checkpointing=True\n",
        "    scheduler='cosine' # ['linear', 'cosine']\n",
        "    batch_scheduler=True\n",
        "    num_cycles=0.5\n",
        "    num_warmup_steps=0\n",
        "    epochs=4\n",
        "    encoder_lr=2e-5\n",
        "    decoder_lr=2e-5\n",
        "    min_lr=1e-6\n",
        "    eps=1e-6\n",
        "    betas=(0.9, 0.999)\n",
        "    batch_size=3\n",
        "    max_len=512\n",
        "    weight_decay=0.01\n",
        "    gradient_accumulation_steps=1\n",
        "    max_grad_norm=1000\n",
        "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "    seed=42\n",
        "    n_fold=4\n",
        "    trn_fold=[0, 1, 2, 3]\n",
        "    train=True\n",
        "    \n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4692bb04",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.297610Z",
          "iopub.status.busy": "2022-08-31T22:31:20.296833Z",
          "iopub.status.idle": "2022-08-31T22:31:29.392500Z",
          "shell.execute_reply": "2022-08-31T22:31:29.391447Z"
        },
        "papermill": {
          "duration": 9.105575,
          "end_time": "2022-08-31T22:31:29.395630",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.290055",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "4692bb04",
        "outputId": "60f45fc7-69d3-4f6c-fd8b-46a87d76721e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
            "Get your W&B access token from here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221124_213730-2dhjpatz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/yanzhen4/FB3-Public/runs/2dhjpatz\" target=\"_blank\">/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large</a></strong> to <a href=\"https://wandb.ai/yanzhen4/FB3-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ====================================================\n",
        "# wandb\n",
        "# ====================================================\n",
        "if CFG.wandb:\n",
        "    \n",
        "    import wandb\n",
        "\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
        "        wandb.login(key=secret_value_0)\n",
        "        anony = None\n",
        "    except:\n",
        "        anony = \"must\"\n",
        "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
        "\n",
        "\n",
        "    def class2dict(f):\n",
        "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
        "\n",
        "    run = wandb.init(project='FB3-Public', \n",
        "                     name=CFG.model,\n",
        "                     config=class2dict(CFG),\n",
        "                     group=CFG.model,\n",
        "                     job_type=\"train\",\n",
        "                     anonymous=anony)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59ce0b2",
      "metadata": {
        "papermill": {
          "duration": 0.009322,
          "end_time": "2022-08-31T22:31:29.415506",
          "exception": false,
          "start_time": "2022-08-31T22:31:29.406184",
          "status": "completed"
        },
        "tags": [],
        "id": "b59ce0b2"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f513d712",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:29.436467Z",
          "iopub.status.busy": "2022-08-31T22:31:29.436018Z",
          "iopub.status.idle": "2022-08-31T22:32:28.081444Z",
          "shell.execute_reply": "2022-08-31T22:32:28.080370Z"
        },
        "papermill": {
          "duration": 58.659308,
          "end_time": "2022-08-31T22:32:28.084435",
          "exception": false,
          "start_time": "2022-08-31T22:31:29.425127",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f513d712",
        "outputId": "c086e42b-3dee-4783-95f7-acaafb50ac48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers.__version__: 4.24.0\n"
          ]
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "#os.system('pip install iterative-stratification==0.1.7')\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#os.system('pip uninstall -y transformers')\n",
        "#os.system('pip uninstall -y tokenizers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels transformers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels tokenizers')\n",
        "#import tokenizers\n",
        "import transformers\n",
        "#print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "#%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c521bb35",
      "metadata": {
        "papermill": {
          "duration": 0.015189,
          "end_time": "2022-08-31T22:32:28.113643",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.098454",
          "status": "completed"
        },
        "tags": [],
        "id": "c521bb35"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "37e2a622",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.142081Z",
          "iopub.status.busy": "2022-08-31T22:32:28.140999Z",
          "iopub.status.idle": "2022-08-31T22:32:28.163185Z",
          "shell.execute_reply": "2022-08-31T22:32:28.162199Z"
        },
        "papermill": {
          "duration": 0.039148,
          "end_time": "2022-08-31T22:32:28.165976",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.126828",
          "status": "completed"
        },
        "tags": [],
        "id": "37e2a622"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "def MCRMSE(y_trues, y_preds): #loss\n",
        "    scores = []\n",
        "    idxes = y_trues.shape[1]\n",
        "    for i in range(idxes):\n",
        "        y_true = y_trues[:,i]\n",
        "        y_pred = y_preds[:,i]\n",
        "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
        "        scores.append(score)\n",
        "    mcrmse_score = np.mean(scores)\n",
        "    return mcrmse_score, scores #score: single prediction result; scores: list of all results\n",
        "\n",
        "\n",
        "def get_score(y_trues, y_preds):\n",
        "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
        "    return mcrmse_score, scores\n",
        "\n",
        "\n",
        "def get_logger(filename=OUTPUT_DIR+'train'): #print log \n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e95c84",
      "metadata": {
        "papermill": {
          "duration": 0.010764,
          "end_time": "2022-08-31T22:32:28.191852",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.181088",
          "status": "completed"
        },
        "tags": [],
        "id": "94e95c84"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "db454733",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.216397Z",
          "iopub.status.busy": "2022-08-31T22:32:28.215550Z",
          "iopub.status.idle": "2022-08-31T22:32:28.504765Z",
          "shell.execute_reply": "2022-08-31T22:32:28.503570Z"
        },
        "papermill": {
          "duration": 0.304959,
          "end_time": "2022-08-31T22:32:28.508101",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.203142",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "db454733",
        "outputId": "087c7bad-f486-48df-c2b1-4f19407de8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (3911, 8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07c4a986-e494-40dd-b192-101da3fa726f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07c4a986-e494-40dd-b192-101da3fa726f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07c4a986-e494-40dd-b192-101da3fa726f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07c4a986-e494-40dd-b192-101da3fa726f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.shape: (3, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id                                          full_text\n",
              "0  0000C359D63E  when a person has no experience on a job their...\n",
              "1  000BAD50D026  Do you think students would benefit from being...\n",
              "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e814eded-570f-4dc7-a69b-10efea5e36ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>when a person has no experience on a job their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>Do you think students would benefit from being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e814eded-570f-4dc7-a69b-10efea5e36ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e814eded-570f-4dc7-a69b-10efea5e36ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e814eded-570f-4dc7-a69b-10efea5e36ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.shape: (3, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0  0000C359D63E       3.0     3.0         3.0          3.0      3.0          3.0\n",
              "1  000BAD50D026       3.0     3.0         3.0          3.0      3.0          3.0\n",
              "2  00367BB2546B       3.0     3.0         3.0          3.0      3.0          3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7ae1a4f-10c9-4df2-bf47-83ec533d29b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7ae1a4f-10c9-4df2-bf47-83ec533d29b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7ae1a4f-10c9-4df2-bf47-83ec533d29b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7ae1a4f-10c9-4df2-bf47-83ec533d29b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Data Loading\n",
        "# ====================================================\n",
        "train = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/train.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/test.csv')\n",
        "submission = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/sample_submission.csv')\n",
        "\n",
        "print(f\"train.shape: {train.shape}\")\n",
        "display(train.head())\n",
        "print(f\"test.shape: {test.shape}\")\n",
        "display(test.head())\n",
        "print(f\"submission.shape: {submission.shape}\")\n",
        "display(submission.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae4a81b",
      "metadata": {
        "papermill": {
          "duration": 0.009487,
          "end_time": "2022-08-31T22:32:28.527661",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.518174",
          "status": "completed"
        },
        "tags": [],
        "id": "dae4a81b"
      },
      "source": [
        "# CV split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "32200ebe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.554307Z",
          "iopub.status.busy": "2022-08-31T22:32:28.553699Z",
          "iopub.status.idle": "2022-08-31T22:32:28.704323Z",
          "shell.execute_reply": "2022-08-31T22:32:28.703340Z"
        },
        "papermill": {
          "duration": 0.164445,
          "end_time": "2022-08-31T22:32:28.706697",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.542252",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "32200ebe",
        "outputId": "be18e2e2-ba73-4f4a-8066-36fd3879fafe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0    978\n",
              "1    977\n",
              "2    978\n",
              "3    978\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ====================================================\n",
        "# CV split\n",
        "# ====================================================\n",
        "Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n",
        "    train.loc[val_index, 'fold'] = int(n)\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "display(train.groupby('fold').size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R33CkEsSpEu",
        "outputId": "b9b6030c-2a6d-4d4b-95f4-f5fe98be8599"
      },
      "id": "-R33CkEsSpEu",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3911"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a025258f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.724353Z",
          "iopub.status.busy": "2022-08-31T22:32:28.724052Z",
          "iopub.status.idle": "2022-08-31T22:32:28.729744Z",
          "shell.execute_reply": "2022-08-31T22:32:28.728851Z"
        },
        "papermill": {
          "duration": 0.016964,
          "end_time": "2022-08-31T22:32:28.731888",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.714924",
          "status": "completed"
        },
        "tags": [],
        "id": "a025258f"
      },
      "outputs": [],
      "source": [
        "if CFG.debug:\n",
        "    display(train.groupby('fold').size())\n",
        "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
        "    display(train.groupby('fold').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2d766a",
      "metadata": {
        "papermill": {
          "duration": 0.007793,
          "end_time": "2022-08-31T22:32:28.747828",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.740035",
          "status": "completed"
        },
        "tags": [],
        "id": "aa2d766a"
      },
      "source": [
        "# tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d2fa845d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.765839Z",
          "iopub.status.busy": "2022-08-31T22:32:28.765473Z",
          "iopub.status.idle": "2022-08-31T22:32:35.437418Z",
          "shell.execute_reply": "2022-08-31T22:32:35.436468Z"
        },
        "papermill": {
          "duration": 6.683936,
          "end_time": "2022-08-31T22:32:35.439931",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.755995",
          "status": "completed"
        },
        "tags": [],
        "id": "d2fa845d"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# tokenizer\n",
        "# ====================================================\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model) #get deberta tokenizer \n",
        "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
        "CFG.tokenizer = tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df117510",
      "metadata": {
        "papermill": {
          "duration": 0.008087,
          "end_time": "2022-08-31T22:32:35.456694",
          "exception": false,
          "start_time": "2022-08-31T22:32:35.448607",
          "status": "completed"
        },
        "tags": [],
        "id": "df117510"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dac78bb9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:35.476349Z",
          "iopub.status.busy": "2022-08-31T22:32:35.475302Z",
          "iopub.status.idle": "2022-08-31T22:32:41.683449Z",
          "shell.execute_reply": "2022-08-31T22:32:41.681990Z"
        },
        "papermill": {
          "duration": 6.221034,
          "end_time": "2022-08-31T22:32:41.686006",
          "exception": false,
          "start_time": "2022-08-31T22:32:35.464972",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "b28978f614ed44cea929d43958cfb805",
            "334322315b2949628a1f4e6bfe8eaa6d",
            "857acd52273645c79b1dc3ea4fe5ebed",
            "0ae0a453e2be4939a3af61578ba7e75e",
            "20e4aec2306b4b34828af01aee0747d1",
            "0d52505015994435a45bd969e29ffaee",
            "6fd28b3cd9c4499cb420aa2031edb1b5",
            "e9a345159ab4481f9b0608bca70019f6",
            "b2c9a86bd5344d65b6b81f5bd52a8bd7",
            "6bbe63369fcf4ebaa78f7ac0bd04e47b",
            "63c4dac9124f48678a7a3d10d636cdb0"
          ]
        },
        "id": "dac78bb9",
        "outputId": "429dcd21-575c-460a-c539-4aaca76f28e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3911 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b28978f614ed44cea929d43958cfb805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "max_len: 5122\n",
            "INFO:__main__:max_len: 5122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5122"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Define max_len\n",
        "# Find max token length after tokenizing each text \n",
        "# ====================================================\n",
        "lengths = []\n",
        "tk0 = tqdm(train['full_text'].fillna(\"\").values, total=len(train))\n",
        "for text in tk0:\n",
        "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "CFG.max_len = max(lengths) + 3 # cls & sep & sep\n",
        "LOGGER.info(f\"max_len: {CFG.max_len}\")\n",
        "CFG.max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "14b26230",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.706635Z",
          "iopub.status.busy": "2022-08-31T22:32:41.704899Z",
          "iopub.status.idle": "2022-08-31T22:32:41.715654Z",
          "shell.execute_reply": "2022-08-31T22:32:41.714775Z"
        },
        "papermill": {
          "duration": 0.022792,
          "end_time": "2022-08-31T22:32:41.717965",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.695173",
          "status": "completed"
        },
        "tags": [],
        "id": "14b26230"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Dataset\n",
        "# ====================================================\n",
        "def prepare_input(cfg, text):\n",
        "    inputs = cfg.tokenizer.encode_plus(\n",
        "        text, \n",
        "        return_tensors=None, \n",
        "        add_special_tokens=True, \n",
        "        max_length=CFG.max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True\n",
        "    )\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "    return inputs #a list of tensors \n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, cfg, df):\n",
        "        self.cfg = cfg\n",
        "        self.texts = df['full_text'].values\n",
        "        self.labels = df[cfg.target_cols].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = prepare_input(self.cfg, self.texts[item])\n",
        "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
        "        return inputs, label\n",
        "    \n",
        "\n",
        "def collate(inputs):\n",
        "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:,:mask_len]\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bda5663",
      "metadata": {
        "papermill": {
          "duration": 0.008337,
          "end_time": "2022-08-31T22:32:41.734920",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.726583",
          "status": "completed"
        },
        "tags": [],
        "id": "2bda5663"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a5f24525",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.754836Z",
          "iopub.status.busy": "2022-08-31T22:32:41.754449Z",
          "iopub.status.idle": "2022-08-31T22:32:41.773130Z",
          "shell.execute_reply": "2022-08-31T22:32:41.769556Z"
        },
        "papermill": {
          "duration": 0.031877,
          "end_time": "2022-08-31T22:32:41.776126",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.744249",
          "status": "completed"
        },
        "tags": [],
        "id": "a5f24525"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Model\n",
        "# ====================================================\n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float() \n",
        "        #last_hidden_state is a list of n tensors, n is sequence length\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        #padding: [PAD] make same length, for [PAD] attention_mask = 0\n",
        "        #last_hidden_state is output of the model\n",
        "        return mean_embeddings\n",
        "    \n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if config_path is None:\n",
        "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True) \n",
        "            #output of every layer during inference\n",
        "            self.config.hidden_dropout = 0.\n",
        "            self.config.hidden_dropout_prob = 0.\n",
        "            self.config.attention_dropout = 0.\n",
        "            self.config.attention_probs_dropout_prob = 0.\n",
        "            LOGGER.info(self.config)\n",
        "        else:\n",
        "            self.config = torch.load(config_path)\n",
        "        if pretrained:\n",
        "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
        "        else:\n",
        "            self.model = AutoModel(self.config)\n",
        "        if self.cfg.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "        self.pool = MeanPooling()\n",
        "        self.fc = nn.Linear(self.config.hidden_size, 6) #hidden_size is input size, 6 is output size \n",
        "        self._init_weights(self.fc)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        \n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        last_hidden_states = outputs[0]\n",
        "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
        "        return feature\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        output = self.fc(feature)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f90882e",
      "metadata": {
        "papermill": {
          "duration": 0.008836,
          "end_time": "2022-08-31T22:32:41.801081",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.792245",
          "status": "completed"
        },
        "tags": [],
        "id": "3f90882e"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4ffd8144",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.819862Z",
          "iopub.status.busy": "2022-08-31T22:32:41.819486Z",
          "iopub.status.idle": "2022-08-31T22:32:41.829800Z",
          "shell.execute_reply": "2022-08-31T22:32:41.827775Z"
        },
        "papermill": {
          "duration": 0.023124,
          "end_time": "2022-08-31T22:32:41.832806",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.809682",
          "status": "completed"
        },
        "tags": [],
        "id": "4ffd8144"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Loss\n",
        "# ====================================================\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, reduction='mean', eps=1e-9):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction='none')\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
        "        if self.reduction == 'none':\n",
        "            loss = loss\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c15011e",
      "metadata": {
        "papermill": {
          "duration": 0.008528,
          "end_time": "2022-08-31T22:32:41.852306",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.843778",
          "status": "completed"
        },
        "tags": [],
        "id": "1c15011e"
      },
      "source": [
        "# Helpler functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c11acdda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.872384Z",
          "iopub.status.busy": "2022-08-31T22:32:41.872032Z",
          "iopub.status.idle": "2022-08-31T22:32:41.892510Z",
          "shell.execute_reply": "2022-08-31T22:32:41.891247Z"
        },
        "papermill": {
          "duration": 0.034604,
          "end_time": "2022-08-31T22:32:41.895844",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.861240",
          "status": "completed"
        },
        "tags": [],
        "id": "c11acdda"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    losses = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        #optimize\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch+1, step, len(train_loader), \n",
        "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
        "                          loss=losses,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
        "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
        "    return losses.avg\n",
        "\n",
        "\n",
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs) #predict\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss=losses,\n",
        "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "730d838d",
      "metadata": {
        "papermill": {
          "duration": 0.008782,
          "end_time": "2022-08-31T22:32:41.916203",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.907421",
          "status": "completed"
        },
        "tags": [],
        "id": "730d838d"
      },
      "source": [
        "# train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "635322a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.935559Z",
          "iopub.status.busy": "2022-08-31T22:32:41.935211Z",
          "iopub.status.idle": "2022-08-31T22:32:41.959171Z",
          "shell.execute_reply": "2022-08-31T22:32:41.956784Z"
        },
        "papermill": {
          "duration": 0.037102,
          "end_time": "2022-08-31T22:32:41.962148",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.925046",
          "status": "completed"
        },
        "tags": [],
        "id": "635322a0"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# train loop\n",
        "# ====================================================\n",
        "def train_loop(folds, fold, unlabled_data): \n",
        "     \n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # loader\n",
        "    # ====================================================\n",
        "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
        "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
        "    valid_labels = valid_folds[CFG.target_cols].values\n",
        "    \n",
        "    train_dataset = TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
        "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
        "    model.to(device)\n",
        "    \n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr, \n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "    \n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "    \n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n",
        "    \n",
        "    best_score = np.inf\n",
        "\n",
        "    # 5 Epoch with origin data\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "         \n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        \n",
        "        # scoring\n",
        "        score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                       f\"[fold{fold}] score\": score})\n",
        "        \n",
        "        if best_score > score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "    \n",
        "    #unlabled_data = old data\n",
        "    pseudoLabel_data = train_folds #dataframe\n",
        "    pesudoLabel_data_len = len(old_data)\n",
        "    sample_size = pesudoLabel_data_len / 5\n",
        "   \n",
        "    # 5 Epochs training with origin data + pseudo-labled data\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        pesudoLabel_data_use = pesudoLabel_data[:sample_size]\n",
        "        pesudoLabel_data = pesudoLabel_data[sample_size:]\n",
        "\n",
        "        #unlabled_data = unlabled_data - sampled_data\n",
        "\n",
        "        for index, text in pesudoLabel_data_use.itterrows():\n",
        "          inputs = collate()\n",
        "          y_preds = model(inputs)\n",
        "          pesudoLabel_data_use[cfg.target_cols] = y_preds\n",
        "        \n",
        "        train_folds = pd.concat(train_folds, pesudoLabel_data_use)\n",
        "        train_dataset = TrainDataset(CFG, train_folds)\n",
        "        train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "            \n",
        "        start_time = time.time()\n",
        "\n",
        "        #predict for all sampled_data, generate labled data\n",
        "        #stack sampled_data on new data\n",
        "        #add to train_loader\n",
        "         \n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        \n",
        "        # scoring\n",
        "        score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                       f\"[fold{fold}] score\": score})\n",
        "        \n",
        "        if best_score > score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
        "                             map_location=torch.device('cpu'))['predictions']\n",
        "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return valid_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07daa080",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.984286Z",
          "iopub.status.busy": "2022-08-31T22:32:41.983961Z",
          "iopub.status.idle": "2022-09-01T01:51:42.378681Z",
          "shell.execute_reply": "2022-09-01T01:51:42.377687Z"
        },
        "papermill": {
          "duration": 11940.406964,
          "end_time": "2022-09-01T01:51:42.380833",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.973869",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "07daa080",
        "outputId": "ce5dae81-bb54-4201-d34d-ccf7ebb44628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 training ==========\n",
            "INFO:__main__:========== fold: 0 training ==========\n",
            "DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/977] Elapsed 0m 5s (remain 91m 54s) Loss: 2.4374(2.4374) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][20/977] Elapsed 0m 23s (remain 17m 51s) Loss: 0.1326(0.7242) Grad: 173043.5625  LR: 0.00002000  \n",
            "Epoch: [1][40/977] Elapsed 0m 31s (remain 12m 4s) Loss: 0.1111(0.4617) Grad: 167739.8438  LR: 0.00001999  \n",
            "Epoch: [1][60/977] Elapsed 0m 41s (remain 10m 30s) Loss: 0.1445(0.3704) Grad: 197188.6875  LR: 0.00001999  \n",
            "Epoch: [1][80/977] Elapsed 0m 49s (remain 9m 5s) Loss: 0.1936(0.3294) Grad: 131596.1406  LR: 0.00001998  \n",
            "Epoch: [1][100/977] Elapsed 0m 57s (remain 8m 16s) Loss: 0.0911(0.2996) Grad: 184314.3281  LR: 0.00001997  \n",
            "Epoch: [1][120/977] Elapsed 1m 4s (remain 7m 35s) Loss: 0.2723(0.2785) Grad: 247484.6406  LR: 0.00001995  \n",
            "Epoch: [1][140/977] Elapsed 1m 13s (remain 7m 17s) Loss: 0.2938(0.2612) Grad: 226818.5312  LR: 0.00001994  \n",
            "Epoch: [1][160/977] Elapsed 1m 37s (remain 8m 12s) Loss: 0.1740(0.2491) Grad: 262119.5000  LR: 0.00001992  \n",
            "Epoch: [1][180/977] Elapsed 1m 46s (remain 7m 47s) Loss: 0.1684(0.2383) Grad: 122255.3438  LR: 0.00001989  \n",
            "Epoch: [1][200/977] Elapsed 1m 56s (remain 7m 29s) Loss: 0.3241(0.2332) Grad: 173189.5469  LR: 0.00001987  \n",
            "Epoch: [1][220/977] Elapsed 2m 6s (remain 7m 13s) Loss: 0.1915(0.2291) Grad: 252253.9062  LR: 0.00001984  \n",
            "Epoch: [1][240/977] Elapsed 2m 15s (remain 6m 53s) Loss: 0.1642(0.2215) Grad: 142025.2031  LR: 0.00001981  \n",
            "Epoch: [1][260/977] Elapsed 2m 23s (remain 6m 34s) Loss: 0.0995(0.2157) Grad: 81841.9609  LR: 0.00001978  \n",
            "Epoch: [1][280/977] Elapsed 2m 33s (remain 6m 21s) Loss: 0.1458(0.2098) Grad: 119907.3594  LR: 0.00001975  \n",
            "Epoch: [1][300/977] Elapsed 2m 43s (remain 6m 7s) Loss: 0.2299(0.2076) Grad: 194080.3281  LR: 0.00001971  \n",
            "Epoch: [1][320/977] Elapsed 2m 54s (remain 5m 56s) Loss: 0.2516(0.2045) Grad: 112521.4297  LR: 0.00001967  \n",
            "Epoch: [1][340/977] Elapsed 3m 2s (remain 5m 39s) Loss: 0.0898(0.2019) Grad: 92684.5156  LR: 0.00001963  \n",
            "Epoch: [1][360/977] Elapsed 3m 10s (remain 5m 24s) Loss: 0.1016(0.1992) Grad: 97167.8594  LR: 0.00001958  \n",
            "Epoch: [1][380/977] Elapsed 3m 19s (remain 5m 12s) Loss: 0.0495(0.1955) Grad: 105047.1094  LR: 0.00001954  \n",
            "Epoch: [1][400/977] Elapsed 3m 26s (remain 4m 57s) Loss: 0.2314(0.1903) Grad: 127159.2578  LR: 0.00001949  \n",
            "Epoch: [1][420/977] Elapsed 3m 44s (remain 4m 56s) Loss: 0.0650(0.1891) Grad: 94727.3750  LR: 0.00001943  \n",
            "Epoch: [1][440/977] Elapsed 3m 52s (remain 4m 42s) Loss: 0.1148(0.1861) Grad: 90199.9375  LR: 0.00001938  \n",
            "Epoch: [1][460/977] Elapsed 4m 2s (remain 4m 30s) Loss: 0.1504(0.1832) Grad: 201102.4062  LR: 0.00001932  \n",
            "Epoch: [1][480/977] Elapsed 4m 11s (remain 4m 19s) Loss: 0.0785(0.1805) Grad: 83029.1641  LR: 0.00001926  \n",
            "Epoch: [1][500/977] Elapsed 4m 19s (remain 4m 6s) Loss: 0.0546(0.1778) Grad: 48892.0273  LR: 0.00001920  \n",
            "Epoch: [1][520/977] Elapsed 4m 38s (remain 4m 3s) Loss: 0.1411(0.1756) Grad: 78553.4375  LR: 0.00001914  \n",
            "Epoch: [1][540/977] Elapsed 4m 47s (remain 3m 51s) Loss: 0.1015(0.1749) Grad: 144904.8594  LR: 0.00001907  \n",
            "Epoch: [1][560/977] Elapsed 5m 1s (remain 3m 43s) Loss: 0.2439(0.1740) Grad: 160657.0781  LR: 0.00001900  \n",
            "Epoch: [1][580/977] Elapsed 5m 13s (remain 3m 33s) Loss: 0.2348(0.1725) Grad: 197039.1562  LR: 0.00001893  \n",
            "Epoch: [1][600/977] Elapsed 5m 24s (remain 3m 22s) Loss: 0.0676(0.1723) Grad: 105843.4453  LR: 0.00001886  \n",
            "Epoch: [1][620/977] Elapsed 5m 32s (remain 3m 10s) Loss: 0.0691(0.1704) Grad: 84775.8906  LR: 0.00001878  \n",
            "Epoch: [1][640/977] Elapsed 5m 40s (remain 2m 58s) Loss: 0.1332(0.1699) Grad: 161727.6250  LR: 0.00001870  \n",
            "Epoch: [1][660/977] Elapsed 5m 53s (remain 2m 49s) Loss: 0.2542(0.1685) Grad: 246837.4531  LR: 0.00001862  \n",
            "Epoch: [1][680/977] Elapsed 6m 4s (remain 2m 38s) Loss: 0.0697(0.1670) Grad: 71346.5000  LR: 0.00001854  \n",
            "Epoch: [1][700/977] Elapsed 6m 15s (remain 2m 27s) Loss: 0.0693(0.1661) Grad: 108431.9062  LR: 0.00001846  \n",
            "Epoch: [1][720/977] Elapsed 6m 27s (remain 2m 17s) Loss: 0.0926(0.1656) Grad: 69399.5312  LR: 0.00001837  \n",
            "Epoch: [1][740/977] Elapsed 6m 35s (remain 2m 6s) Loss: 0.0883(0.1644) Grad: 73073.6328  LR: 0.00001828  \n",
            "Epoch: [1][760/977] Elapsed 6m 44s (remain 1m 54s) Loss: 0.0515(0.1635) Grad: 79988.2656  LR: 0.00001819  \n",
            "Epoch: [1][780/977] Elapsed 6m 55s (remain 1m 44s) Loss: 0.1575(0.1622) Grad: 132435.3750  LR: 0.00001809  \n",
            "Epoch: [1][800/977] Elapsed 7m 12s (remain 1m 34s) Loss: 0.0853(0.1613) Grad: 76165.0625  LR: 0.00001800  \n",
            "Epoch: [1][820/977] Elapsed 7m 19s (remain 1m 23s) Loss: 0.1419(0.1609) Grad: 140127.8125  LR: 0.00001790  \n",
            "Epoch: [1][840/977] Elapsed 7m 30s (remain 1m 12s) Loss: 0.1359(0.1602) Grad: 144024.4531  LR: 0.00001780  \n",
            "Epoch: [1][860/977] Elapsed 7m 39s (remain 1m 1s) Loss: 0.0715(0.1588) Grad: 122765.1641  LR: 0.00001770  \n",
            "Epoch: [1][880/977] Elapsed 7m 46s (remain 0m 50s) Loss: 0.1781(0.1583) Grad: 128496.3750  LR: 0.00001760  \n",
            "Epoch: [1][900/977] Elapsed 7m 54s (remain 0m 40s) Loss: 0.3195(0.1574) Grad: 131745.1719  LR: 0.00001749  \n",
            "Epoch: [1][920/977] Elapsed 8m 7s (remain 0m 29s) Loss: 0.0883(0.1565) Grad: 108641.5469  LR: 0.00001738  \n",
            "Epoch: [1][940/977] Elapsed 8m 18s (remain 0m 19s) Loss: 0.1423(0.1563) Grad: 75889.7812  LR: 0.00001728  \n",
            "Epoch: [1][960/977] Elapsed 8m 26s (remain 0m 8s) Loss: 0.0800(0.1561) Grad: 90432.9922  LR: 0.00001716  \n",
            "Epoch: [1][976/977] Elapsed 8m 33s (remain 0m 0s) Loss: 0.0889(0.1553) Grad: 64855.6523  LR: 0.00001707  \n",
            "EVAL: [0/163] Elapsed 0m 0s (remain 2m 22s) Loss: 0.0759(0.0759) \n",
            "EVAL: [20/163] Elapsed 0m 10s (remain 1m 13s) Loss: 0.0754(0.1132) \n",
            "EVAL: [40/163] Elapsed 0m 21s (remain 1m 2s) Loss: 0.1388(0.1137) \n",
            "EVAL: [60/163] Elapsed 0m 32s (remain 0m 55s) Loss: 0.1001(0.1157) \n",
            "EVAL: [80/163] Elapsed 0m 43s (remain 0m 43s) Loss: 0.1225(0.1147) \n",
            "EVAL: [100/163] Elapsed 0m 51s (remain 0m 31s) Loss: 0.0925(0.1156) \n",
            "EVAL: [120/163] Elapsed 1m 1s (remain 0m 21s) Loss: 0.0859(0.1143) \n",
            "EVAL: [140/163] Elapsed 1m 9s (remain 0m 10s) Loss: 0.0994(0.1150) \n",
            "EVAL: [160/163] Elapsed 1m 20s (remain 0m 1s) Loss: 0.1661(0.1173) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.1553  avg_val_loss: 0.1167  time: 595s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.1553  avg_val_loss: 0.1167  time: 595s\n",
            "Epoch 1 - Score: 0.4844  Scores: [0.515602484608563, 0.4666553965830531, 0.43848137497497947, 0.48522324372243164, 0.5310280291689138, 0.4696097512743176]\n",
            "INFO:__main__:Epoch 1 - Score: 0.4844  Scores: [0.515602484608563, 0.4666553965830531, 0.43848137497497947, 0.48522324372243164, 0.5310280291689138, 0.4696097512743176]\n",
            "Epoch 1 - Save Best Score: 0.4844 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.4844 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [162/163] Elapsed 1m 21s (remain 0m 0s) Loss: 0.0493(0.1167) \n",
            "Epoch: [2][0/977] Elapsed 0m 0s (remain 9m 31s) Loss: 0.0627(0.0627) Grad: 163956.9062  LR: 0.00001707  \n",
            "Epoch: [2][20/977] Elapsed 0m 12s (remain 9m 9s) Loss: 0.0723(0.1065) Grad: 59454.5742  LR: 0.00001695  \n",
            "Epoch: [2][40/977] Elapsed 0m 23s (remain 8m 48s) Loss: 0.1193(0.1163) Grad: 178211.0625  LR: 0.00001684  \n",
            "Epoch: [2][60/977] Elapsed 0m 31s (remain 7m 47s) Loss: 0.1252(0.1128) Grad: 105106.8984  LR: 0.00001672  \n",
            "Epoch: [2][80/977] Elapsed 0m 39s (remain 7m 14s) Loss: 0.0743(0.1121) Grad: 66195.9219  LR: 0.00001660  \n",
            "Epoch: [2][100/977] Elapsed 0m 48s (remain 6m 59s) Loss: 0.0406(0.1088) Grad: 39490.8906  LR: 0.00001648  \n",
            "Epoch: [2][120/977] Elapsed 1m 8s (remain 8m 7s) Loss: 0.0834(0.1110) Grad: 89611.0703  LR: 0.00001635  \n",
            "Epoch: [2][140/977] Elapsed 1m 22s (remain 8m 11s) Loss: 0.0835(0.1099) Grad: 101555.7422  LR: 0.00001623  \n",
            "Epoch: [2][160/977] Elapsed 1m 32s (remain 7m 47s) Loss: 0.0515(0.1070) Grad: 77056.9766  LR: 0.00001610  \n",
            "Epoch: [2][180/977] Elapsed 1m 40s (remain 7m 20s) Loss: 0.2153(0.1068) Grad: 106946.5391  LR: 0.00001597  \n",
            "Epoch: [2][200/977] Elapsed 1m 48s (remain 6m 59s) Loss: 0.1075(0.1069) Grad: 88564.6953  LR: 0.00001585  \n",
            "Epoch: [2][220/977] Elapsed 1m 59s (remain 6m 48s) Loss: 0.1259(0.1090) Grad: 141129.1875  LR: 0.00001571  \n",
            "Epoch: [2][240/977] Elapsed 2m 9s (remain 6m 35s) Loss: 0.0754(0.1089) Grad: 63914.1289  LR: 0.00001558  \n",
            "Epoch: [2][260/977] Elapsed 2m 19s (remain 6m 22s) Loss: 0.0558(0.1072) Grad: 48962.6133  LR: 0.00001545  \n",
            "Epoch: [2][280/977] Elapsed 2m 27s (remain 6m 4s) Loss: 0.1538(0.1050) Grad: 149785.2969  LR: 0.00001531  \n",
            "Epoch: [2][300/977] Elapsed 2m 35s (remain 5m 50s) Loss: 0.0479(0.1067) Grad: 87416.1641  LR: 0.00001518  \n",
            "Epoch: [2][320/977] Elapsed 2m 43s (remain 5m 33s) Loss: 0.0817(0.1060) Grad: 75978.7031  LR: 0.00001504  \n",
            "Epoch: [2][340/977] Elapsed 2m 50s (remain 5m 17s) Loss: 0.0699(0.1051) Grad: 98970.8672  LR: 0.00001490  \n",
            "Epoch: [2][360/977] Elapsed 3m 0s (remain 5m 8s) Loss: 0.0559(0.1057) Grad: 66949.2812  LR: 0.00001476  \n",
            "Epoch: [2][380/977] Elapsed 3m 9s (remain 4m 56s) Loss: 0.1103(0.1052) Grad: 100933.4062  LR: 0.00001461  \n",
            "Epoch: [2][400/977] Elapsed 3m 20s (remain 4m 48s) Loss: 0.0719(0.1053) Grad: 63913.9727  LR: 0.00001447  \n",
            "Epoch: [2][420/977] Elapsed 3m 30s (remain 4m 37s) Loss: 0.0999(0.1056) Grad: 158870.6094  LR: 0.00001433  \n",
            "Epoch: [2][440/977] Elapsed 3m 43s (remain 4m 32s) Loss: 0.0874(0.1062) Grad: 65100.5859  LR: 0.00001418  \n",
            "Epoch: [2][460/977] Elapsed 3m 52s (remain 4m 19s) Loss: 0.1127(0.1065) Grad: 149450.8906  LR: 0.00001404  \n",
            "Epoch: [2][480/977] Elapsed 4m 10s (remain 4m 18s) Loss: 0.1260(0.1067) Grad: 88536.7344  LR: 0.00001389  \n",
            "Epoch: [2][500/977] Elapsed 4m 19s (remain 4m 6s) Loss: 0.2041(0.1061) Grad: 213988.4531  LR: 0.00001374  \n",
            "Epoch: [2][520/977] Elapsed 4m 28s (remain 3m 55s) Loss: 0.1174(0.1055) Grad: 83034.4531  LR: 0.00001359  \n",
            "Epoch: [2][540/977] Elapsed 4m 39s (remain 3m 44s) Loss: 0.1455(0.1056) Grad: 95784.6250  LR: 0.00001344  \n",
            "Epoch: [2][560/977] Elapsed 4m 50s (remain 3m 35s) Loss: 0.0691(0.1059) Grad: 70143.6016  LR: 0.00001329  \n",
            "Epoch: [2][580/977] Elapsed 4m 57s (remain 3m 22s) Loss: 0.0967(0.1055) Grad: 74612.2656  LR: 0.00001314  \n",
            "Epoch: [2][600/977] Elapsed 5m 6s (remain 3m 11s) Loss: 0.0681(0.1051) Grad: 80271.5703  LR: 0.00001298  \n",
            "Epoch: [2][620/977] Elapsed 5m 15s (remain 3m 0s) Loss: 0.0817(0.1057) Grad: 120384.2031  LR: 0.00001283  \n",
            "Epoch: [2][640/977] Elapsed 5m 23s (remain 2m 49s) Loss: 0.0627(0.1053) Grad: 48264.8203  LR: 0.00001267  \n",
            "Epoch: [2][660/977] Elapsed 5m 33s (remain 2m 39s) Loss: 0.0813(0.1045) Grad: 92787.7656  LR: 0.00001252  \n",
            "Epoch: [2][680/977] Elapsed 5m 55s (remain 2m 34s) Loss: 0.0662(0.1043) Grad: 83474.2891  LR: 0.00001236  \n",
            "Epoch: [2][700/977] Elapsed 6m 4s (remain 2m 23s) Loss: 0.0582(0.1047) Grad: 71963.8125  LR: 0.00001221  \n",
            "Epoch: [2][720/977] Elapsed 6m 15s (remain 2m 13s) Loss: 0.1444(0.1047) Grad: 105022.4297  LR: 0.00001205  \n",
            "Epoch: [2][740/977] Elapsed 6m 24s (remain 2m 2s) Loss: 0.0389(0.1043) Grad: 55562.5820  LR: 0.00001189  \n",
            "Epoch: [2][760/977] Elapsed 6m 35s (remain 1m 52s) Loss: 0.1905(0.1040) Grad: 153338.2031  LR: 0.00001173  \n",
            "Epoch: [2][780/977] Elapsed 6m 45s (remain 1m 41s) Loss: 0.0623(0.1043) Grad: 65312.3516  LR: 0.00001158  \n",
            "Epoch: [2][800/977] Elapsed 6m 53s (remain 1m 30s) Loss: 0.0299(0.1035) Grad: 64077.3594  LR: 0.00001142  \n",
            "Epoch: [2][820/977] Elapsed 7m 1s (remain 1m 20s) Loss: 0.0988(0.1032) Grad: 89583.9453  LR: 0.00001126  \n",
            "Epoch: [2][840/977] Elapsed 7m 19s (remain 1m 11s) Loss: 0.2340(0.1034) Grad: 132456.4531  LR: 0.00001110  \n",
            "Epoch: [2][860/977] Elapsed 7m 27s (remain 1m 0s) Loss: 0.1447(0.1032) Grad: 117353.3047  LR: 0.00001094  \n",
            "Epoch: [2][880/977] Elapsed 7m 37s (remain 0m 49s) Loss: 0.1039(0.1029) Grad: 93725.6172  LR: 0.00001078  \n",
            "Epoch: [2][900/977] Elapsed 7m 44s (remain 0m 39s) Loss: 0.0802(0.1026) Grad: 127029.1328  LR: 0.00001062  \n",
            "Epoch: [2][920/977] Elapsed 7m 56s (remain 0m 28s) Loss: 0.1321(0.1028) Grad: 107369.7734  LR: 0.00001046  \n",
            "Epoch: [2][940/977] Elapsed 8m 7s (remain 0m 18s) Loss: 0.1256(0.1025) Grad: 135958.2656  LR: 0.00001030  \n",
            "Epoch: [2][960/977] Elapsed 8m 16s (remain 0m 8s) Loss: 0.0403(0.1023) Grad: 66958.3828  LR: 0.00001014  \n",
            "Epoch: [2][976/977] Elapsed 8m 22s (remain 0m 0s) Loss: 0.1355(0.1024) Grad: 88803.1328  LR: 0.00001001  \n",
            "EVAL: [0/163] Elapsed 0m 0s (remain 2m 27s) Loss: 0.0728(0.0728) \n",
            "EVAL: [20/163] Elapsed 0m 10s (remain 1m 13s) Loss: 0.0821(0.1027) \n",
            "EVAL: [40/163] Elapsed 0m 21s (remain 1m 2s) Loss: 0.0898(0.1055) \n",
            "EVAL: [60/163] Elapsed 0m 32s (remain 0m 55s) Loss: 0.1145(0.1050) \n",
            "EVAL: [80/163] Elapsed 0m 43s (remain 0m 43s) Loss: 0.1233(0.1057) \n",
            "EVAL: [100/163] Elapsed 0m 51s (remain 0m 31s) Loss: 0.0683(0.1078) \n",
            "EVAL: [120/163] Elapsed 1m 1s (remain 0m 21s) Loss: 0.1044(0.1066) \n",
            "EVAL: [140/163] Elapsed 1m 9s (remain 0m 10s) Loss: 0.1061(0.1072) \n",
            "EVAL: [160/163] Elapsed 1m 20s (remain 0m 1s) Loss: 0.1683(0.1077) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1024  avg_val_loss: 0.1073  time: 584s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1024  avg_val_loss: 0.1073  time: 584s\n",
            "Epoch 2 - Score: 0.4641  Scores: [0.49885895230428484, 0.44758354638883435, 0.4240193041062165, 0.4608765040398254, 0.4841045125056957, 0.4693188988010673]\n",
            "INFO:__main__:Epoch 2 - Score: 0.4641  Scores: [0.49885895230428484, 0.44758354638883435, 0.4240193041062165, 0.4608765040398254, 0.4841045125056957, 0.4693188988010673]\n",
            "Epoch 2 - Save Best Score: 0.4641 Model\n",
            "INFO:__main__:Epoch 2 - Save Best Score: 0.4641 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [162/163] Elapsed 1m 21s (remain 0m 0s) Loss: 0.0650(0.1073) \n",
            "Epoch: [3][0/977] Elapsed 0m 0s (remain 11m 14s) Loss: 0.0321(0.0321) Grad: 97409.7656  LR: 0.00001000  \n",
            "Epoch: [3][20/977] Elapsed 0m 9s (remain 7m 25s) Loss: 0.0322(0.0638) Grad: 121934.5703  LR: 0.00000984  \n",
            "Epoch: [3][40/977] Elapsed 0m 25s (remain 9m 51s) Loss: 0.0827(0.0744) Grad: 180708.3594  LR: 0.00000968  \n",
            "Epoch: [3][60/977] Elapsed 0m 34s (remain 8m 34s) Loss: 0.0637(0.0729) Grad: 115004.3750  LR: 0.00000952  \n",
            "Epoch: [3][80/977] Elapsed 0m 45s (remain 8m 23s) Loss: 0.0556(0.0729) Grad: 93031.3828  LR: 0.00000936  \n",
            "Epoch: [3][100/977] Elapsed 0m 53s (remain 7m 45s) Loss: 0.0998(0.0747) Grad: 255383.9844  LR: 0.00000920  \n",
            "Epoch: [3][120/977] Elapsed 1m 1s (remain 7m 18s) Loss: 0.0261(0.0738) Grad: 82430.6406  LR: 0.00000904  \n",
            "Epoch: [3][140/977] Elapsed 1m 9s (remain 6m 50s) Loss: 0.1305(0.0727) Grad: 282474.4062  LR: 0.00000888  \n",
            "Epoch: [3][160/977] Elapsed 1m 17s (remain 6m 32s) Loss: 0.1168(0.0716) Grad: 134037.6719  LR: 0.00000872  \n",
            "Epoch: [3][180/977] Elapsed 1m 32s (remain 6m 46s) Loss: 0.0419(0.0720) Grad: 115774.6172  LR: 0.00000856  \n",
            "Epoch: [3][200/977] Elapsed 1m 43s (remain 6m 40s) Loss: 0.0409(0.0715) Grad: 97382.4609  LR: 0.00000840  \n",
            "Epoch: [3][220/977] Elapsed 1m 51s (remain 6m 21s) Loss: 0.1049(0.0703) Grad: 265168.6875  LR: 0.00000824  \n",
            "Epoch: [3][240/977] Elapsed 2m 0s (remain 6m 9s) Loss: 0.0533(0.0709) Grad: 193977.0781  LR: 0.00000808  \n",
            "Epoch: [3][260/977] Elapsed 2m 10s (remain 5m 57s) Loss: 0.1259(0.0707) Grad: 168550.7656  LR: 0.00000793  \n",
            "Epoch: [3][280/977] Elapsed 2m 18s (remain 5m 43s) Loss: 0.0591(0.0708) Grad: 136115.1094  LR: 0.00000777  \n",
            "Epoch: [3][300/977] Elapsed 2m 29s (remain 5m 36s) Loss: 0.1353(0.0706) Grad: 125085.6406  LR: 0.00000761  \n",
            "Epoch: [3][320/977] Elapsed 2m 37s (remain 5m 22s) Loss: 0.0743(0.0712) Grad: 143564.3125  LR: 0.00000746  \n",
            "Epoch: [3][340/977] Elapsed 2m 45s (remain 5m 9s) Loss: 0.0406(0.0718) Grad: 112408.5547  LR: 0.00000730  \n",
            "Epoch: [3][360/977] Elapsed 2m 58s (remain 5m 4s) Loss: 0.0488(0.0711) Grad: 155003.0000  LR: 0.00000715  \n",
            "Epoch: [3][380/977] Elapsed 3m 8s (remain 4m 54s) Loss: 0.0723(0.0710) Grad: 149753.9688  LR: 0.00000699  \n",
            "Epoch: [3][400/977] Elapsed 3m 16s (remain 4m 42s) Loss: 0.0460(0.0716) Grad: 135024.2188  LR: 0.00000684  \n",
            "Epoch: [3][420/977] Elapsed 3m 26s (remain 4m 32s) Loss: 0.0468(0.0708) Grad: 166531.9375  LR: 0.00000669  \n",
            "Epoch: [3][440/977] Elapsed 3m 37s (remain 4m 23s) Loss: 0.0619(0.0707) Grad: 118721.1875  LR: 0.00000654  \n",
            "Epoch: [3][460/977] Elapsed 3m 46s (remain 4m 12s) Loss: 0.0506(0.0708) Grad: 130191.2812  LR: 0.00000639  \n",
            "Epoch: [3][480/977] Elapsed 3m 59s (remain 4m 6s) Loss: 0.0343(0.0709) Grad: 135445.7500  LR: 0.00000624  \n",
            "Epoch: [3][500/977] Elapsed 4m 8s (remain 3m 55s) Loss: 0.0612(0.0706) Grad: 188401.6094  LR: 0.00000609  \n",
            "Epoch: [3][520/977] Elapsed 4m 17s (remain 3m 45s) Loss: 0.0775(0.0704) Grad: 193554.7031  LR: 0.00000594  \n",
            "Epoch: [3][540/977] Elapsed 4m 24s (remain 3m 33s) Loss: 0.0726(0.0702) Grad: 142861.2812  LR: 0.00000580  \n",
            "Epoch: [3][560/977] Elapsed 4m 33s (remain 3m 22s) Loss: 0.0889(0.0699) Grad: 167672.7656  LR: 0.00000565  \n",
            "Epoch: [3][580/977] Elapsed 4m 41s (remain 3m 12s) Loss: 0.0530(0.0698) Grad: 126224.5078  LR: 0.00000551  \n",
            "Epoch: [3][600/977] Elapsed 4m 49s (remain 3m 1s) Loss: 0.0618(0.0697) Grad: 123827.2812  LR: 0.00000536  \n",
            "Epoch: [3][620/977] Elapsed 5m 6s (remain 2m 55s) Loss: 0.0616(0.0696) Grad: 193816.6406  LR: 0.00000522  \n",
            "Epoch: [3][640/977] Elapsed 5m 16s (remain 2m 45s) Loss: 0.1414(0.0696) Grad: 203427.7188  LR: 0.00000508  \n",
            "Epoch: [3][660/977] Elapsed 5m 23s (remain 2m 34s) Loss: 0.0443(0.0695) Grad: 161036.6875  LR: 0.00000494  \n",
            "Epoch: [3][680/977] Elapsed 5m 32s (remain 2m 24s) Loss: 0.0590(0.0693) Grad: 164538.5938  LR: 0.00000480  \n",
            "Epoch: [3][700/977] Elapsed 5m 41s (remain 2m 14s) Loss: 0.1404(0.0694) Grad: 236371.9375  LR: 0.00000467  \n",
            "Epoch: [3][720/977] Elapsed 5m 49s (remain 2m 4s) Loss: 0.0295(0.0694) Grad: 117565.3750  LR: 0.00000453  \n",
            "Epoch: [3][740/977] Elapsed 6m 0s (remain 1m 54s) Loss: 0.0618(0.0694) Grad: 184829.9375  LR: 0.00000440  \n",
            "Epoch: [3][760/977] Elapsed 6m 8s (remain 1m 44s) Loss: 0.1236(0.0695) Grad: 342203.5625  LR: 0.00000427  \n",
            "Epoch: [3][780/977] Elapsed 6m 43s (remain 1m 41s) Loss: 0.0683(0.0693) Grad: 191780.3906  LR: 0.00000414  \n",
            "Epoch: [3][800/977] Elapsed 6m 51s (remain 1m 30s) Loss: 0.0530(0.0690) Grad: 125355.8672  LR: 0.00000401  \n",
            "Epoch: [3][820/977] Elapsed 6m 58s (remain 1m 19s) Loss: 0.0846(0.0689) Grad: 217873.2656  LR: 0.00000388  \n",
            "Epoch: [3][840/977] Elapsed 7m 7s (remain 1m 9s) Loss: 0.0469(0.0688) Grad: 119512.9609  LR: 0.00000375  \n",
            "Epoch: [3][860/977] Elapsed 7m 24s (remain 0m 59s) Loss: 0.0514(0.0686) Grad: 94794.4453  LR: 0.00000363  \n",
            "Epoch: [3][880/977] Elapsed 7m 32s (remain 0m 49s) Loss: 0.0851(0.0685) Grad: 173093.7188  LR: 0.00000350  \n",
            "Epoch: [3][900/977] Elapsed 7m 43s (remain 0m 39s) Loss: 0.0833(0.0685) Grad: 201040.1094  LR: 0.00000338  \n",
            "Epoch: [3][920/977] Elapsed 7m 58s (remain 0m 29s) Loss: 0.1152(0.0685) Grad: 257408.7344  LR: 0.00000326  \n",
            "Epoch: [3][940/977] Elapsed 8m 8s (remain 0m 18s) Loss: 0.0522(0.0684) Grad: 136170.1719  LR: 0.00000315  \n",
            "Epoch: [3][960/977] Elapsed 8m 15s (remain 0m 8s) Loss: 0.0584(0.0684) Grad: 163099.2188  LR: 0.00000303  \n",
            "Epoch: [3][976/977] Elapsed 8m 21s (remain 0m 0s) Loss: 0.0497(0.0683) Grad: 111402.0391  LR: 0.00000294  \n",
            "EVAL: [0/163] Elapsed 0m 0s (remain 2m 12s) Loss: 0.0573(0.0573) \n",
            "EVAL: [20/163] Elapsed 0m 10s (remain 1m 12s) Loss: 0.0644(0.1002) \n",
            "EVAL: [40/163] Elapsed 0m 20s (remain 1m 2s) Loss: 0.0915(0.1031) \n",
            "EVAL: [60/163] Elapsed 0m 32s (remain 0m 54s) Loss: 0.0842(0.1023) \n",
            "EVAL: [80/163] Elapsed 0m 43s (remain 0m 43s) Loss: 0.1093(0.1020) \n",
            "EVAL: [100/163] Elapsed 0m 51s (remain 0m 31s) Loss: 0.0669(0.1050) \n",
            "EVAL: [120/163] Elapsed 1m 0s (remain 0m 21s) Loss: 0.0865(0.1041) \n",
            "EVAL: [140/163] Elapsed 1m 9s (remain 0m 10s) Loss: 0.1062(0.1045) \n",
            "EVAL: [160/163] Elapsed 1m 20s (remain 0m 1s) Loss: 0.1496(0.1048) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0683  avg_val_loss: 0.1045  time: 583s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.0683  avg_val_loss: 0.1045  time: 583s\n",
            "Epoch 3 - Score: 0.4579  Scores: [0.48462708949956534, 0.447395850682316, 0.41952328993518256, 0.46227964028327867, 0.483915213992011, 0.4494125248458981]\n",
            "INFO:__main__:Epoch 3 - Score: 0.4579  Scores: [0.48462708949956534, 0.447395850682316, 0.41952328993518256, 0.46227964028327867, 0.483915213992011, 0.4494125248458981]\n",
            "Epoch 3 - Save Best Score: 0.4579 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4579 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [162/163] Elapsed 1m 21s (remain 0m 0s) Loss: 0.0716(0.1045) \n",
            "Epoch: [4][0/977] Elapsed 0m 0s (remain 10m 51s) Loss: 0.0680(0.0680) Grad: 143907.9219  LR: 0.00000293  \n",
            "Epoch: [4][20/977] Elapsed 0m 10s (remain 8m 8s) Loss: 0.0421(0.0593) Grad: 129093.4062  LR: 0.00000282  \n",
            "Epoch: [4][40/977] Elapsed 0m 19s (remain 7m 22s) Loss: 0.0127(0.0551) Grad: 56993.6602  LR: 0.00000271  \n",
            "Epoch: [4][60/977] Elapsed 0m 33s (remain 8m 19s) Loss: 0.0598(0.0569) Grad: 155747.3281  LR: 0.00000260  \n",
            "Epoch: [4][80/977] Elapsed 0m 41s (remain 7m 34s) Loss: 0.0440(0.0554) Grad: 131628.7031  LR: 0.00000249  \n",
            "Epoch: [4][100/977] Elapsed 1m 3s (remain 9m 8s) Loss: 0.0520(0.0552) Grad: 107984.9219  LR: 0.00000239  \n",
            "Epoch: [4][120/977] Elapsed 1m 12s (remain 8m 30s) Loss: 0.0355(0.0545) Grad: 131240.9844  LR: 0.00000228  \n",
            "Epoch: [4][140/977] Elapsed 1m 23s (remain 8m 16s) Loss: 0.0462(0.0556) Grad: 152891.6406  LR: 0.00000218  \n",
            "Epoch: [4][160/977] Elapsed 1m 35s (remain 8m 2s) Loss: 0.0393(0.0553) Grad: 123150.1484  LR: 0.00000208  \n",
            "Epoch: [4][180/977] Elapsed 1m 44s (remain 7m 38s) Loss: 0.0437(0.0552) Grad: 155542.7500  LR: 0.00000199  \n",
            "Epoch: [4][200/977] Elapsed 1m 55s (remain 7m 25s) Loss: 0.0557(0.0553) Grad: 199759.4531  LR: 0.00000189  \n",
            "Epoch: [4][220/977] Elapsed 2m 14s (remain 7m 41s) Loss: 0.0334(0.0558) Grad: 131488.8594  LR: 0.00000180  \n",
            "Epoch: [4][240/977] Elapsed 2m 27s (remain 7m 30s) Loss: 0.0383(0.0558) Grad: 126252.0312  LR: 0.00000171  \n",
            "Epoch: [4][260/977] Elapsed 2m 37s (remain 7m 11s) Loss: 0.0665(0.0554) Grad: 170499.7812  LR: 0.00000162  \n",
            "Epoch: [4][280/977] Elapsed 2m 49s (remain 6m 58s) Loss: 0.1060(0.0553) Grad: 207343.6562  LR: 0.00000153  \n",
            "Epoch: [4][300/977] Elapsed 2m 57s (remain 6m 39s) Loss: 0.0637(0.0557) Grad: 93121.7812  LR: 0.00000145  \n",
            "Epoch: [4][320/977] Elapsed 3m 5s (remain 6m 20s) Loss: 0.0691(0.0560) Grad: 161201.1875  LR: 0.00000137  \n",
            "Epoch: [4][340/977] Elapsed 3m 15s (remain 6m 4s) Loss: 0.0489(0.0555) Grad: 163896.0000  LR: 0.00000129  \n",
            "Epoch: [4][360/977] Elapsed 3m 22s (remain 5m 46s) Loss: 0.0414(0.0557) Grad: 149407.2031  LR: 0.00000121  \n",
            "Epoch: [4][380/977] Elapsed 3m 35s (remain 5m 37s) Loss: 0.0704(0.0554) Grad: 138851.2969  LR: 0.00000113  \n",
            "Epoch: [4][400/977] Elapsed 3m 52s (remain 5m 34s) Loss: 0.0644(0.0553) Grad: 203504.8281  LR: 0.00000106  \n",
            "Epoch: [4][420/977] Elapsed 3m 58s (remain 5m 15s) Loss: 0.0377(0.0548) Grad: 102159.3750  LR: 0.00000099  \n",
            "Epoch: [4][440/977] Elapsed 4m 11s (remain 5m 5s) Loss: 0.0207(0.0546) Grad: 63336.2109  LR: 0.00000092  \n",
            "Epoch: [4][460/977] Elapsed 4m 19s (remain 4m 50s) Loss: 0.0726(0.0548) Grad: 149533.6562  LR: 0.00000085  \n",
            "Epoch: [4][480/977] Elapsed 4m 27s (remain 4m 35s) Loss: 0.0316(0.0545) Grad: 101401.0781  LR: 0.00000079  \n",
            "Epoch: [4][500/977] Elapsed 4m 36s (remain 4m 22s) Loss: 0.0707(0.0543) Grad: 160637.5469  LR: 0.00000073  \n",
            "Epoch: [4][520/977] Elapsed 4m 45s (remain 4m 9s) Loss: 0.0351(0.0544) Grad: 145659.7500  LR: 0.00000067  \n",
            "Epoch: [4][540/977] Elapsed 4m 53s (remain 3m 56s) Loss: 0.0364(0.0546) Grad: 171204.4531  LR: 0.00000061  \n",
            "Epoch: [4][560/977] Elapsed 5m 1s (remain 3m 43s) Loss: 0.0506(0.0546) Grad: 168152.8438  LR: 0.00000056  \n",
            "Epoch: [4][580/977] Elapsed 5m 9s (remain 3m 30s) Loss: 0.0488(0.0544) Grad: 100098.3672  LR: 0.00000051  \n",
            "Epoch: [4][600/977] Elapsed 5m 21s (remain 3m 21s) Loss: 0.0654(0.0543) Grad: 142728.4375  LR: 0.00000046  \n",
            "Epoch: [4][620/977] Elapsed 5m 29s (remain 3m 9s) Loss: 0.0551(0.0546) Grad: 126769.0938  LR: 0.00000041  \n",
            "Epoch: [4][640/977] Elapsed 5m 37s (remain 2m 57s) Loss: 0.0397(0.0546) Grad: 89463.8203  LR: 0.00000037  \n",
            "Epoch: [4][660/977] Elapsed 5m 47s (remain 2m 45s) Loss: 0.0383(0.0544) Grad: 119889.0000  LR: 0.00000032  \n",
            "Epoch: [4][680/977] Elapsed 6m 7s (remain 2m 39s) Loss: 0.0263(0.0543) Grad: 100462.0391  LR: 0.00000029  \n",
            "Epoch: [4][700/977] Elapsed 6m 15s (remain 2m 27s) Loss: 0.0538(0.0543) Grad: 149279.1875  LR: 0.00000025  \n",
            "Epoch: [4][720/977] Elapsed 6m 24s (remain 2m 16s) Loss: 0.0324(0.0543) Grad: 93326.3438  LR: 0.00000021  \n",
            "Epoch: [4][740/977] Elapsed 6m 33s (remain 2m 5s) Loss: 0.0452(0.0542) Grad: 114923.3516  LR: 0.00000018  \n",
            "Epoch: [4][760/977] Elapsed 6m 43s (remain 1m 54s) Loss: 0.0370(0.0542) Grad: 91840.9766  LR: 0.00000015  \n",
            "Epoch: [4][780/977] Elapsed 6m 53s (remain 1m 43s) Loss: 0.0726(0.0540) Grad: 131313.7969  LR: 0.00000013  \n",
            "Epoch: [4][800/977] Elapsed 7m 2s (remain 1m 32s) Loss: 0.0427(0.0540) Grad: 171756.0625  LR: 0.00000010  \n",
            "Epoch: [4][820/977] Elapsed 7m 10s (remain 1m 21s) Loss: 0.0367(0.0538) Grad: 125596.8281  LR: 0.00000008  \n",
            "Epoch: [4][840/977] Elapsed 7m 18s (remain 1m 10s) Loss: 0.1109(0.0538) Grad: 145551.4688  LR: 0.00000006  \n",
            "Epoch: [4][860/977] Elapsed 7m 26s (remain 1m 0s) Loss: 0.0409(0.0538) Grad: 74833.3594  LR: 0.00000004  \n",
            "Epoch: [4][880/977] Elapsed 7m 37s (remain 0m 49s) Loss: 0.0684(0.0537) Grad: 221255.8750  LR: 0.00000003  \n",
            "Epoch: [4][900/977] Elapsed 7m 46s (remain 0m 39s) Loss: 0.0305(0.0537) Grad: 140820.9844  LR: 0.00000002  \n",
            "Epoch: [4][920/977] Elapsed 7m 54s (remain 0m 28s) Loss: 0.0688(0.0537) Grad: 160648.1719  LR: 0.00000001  \n",
            "Epoch: [4][940/977] Elapsed 8m 4s (remain 0m 18s) Loss: 0.0720(0.0538) Grad: 187852.3281  LR: 0.00000000  \n",
            "Epoch: [4][960/977] Elapsed 8m 14s (remain 0m 8s) Loss: 0.0716(0.0539) Grad: 156713.5000  LR: 0.00000000  \n",
            "Epoch: [4][976/977] Elapsed 8m 20s (remain 0m 0s) Loss: 0.0303(0.0539) Grad: 110016.2109  LR: 0.00000000  \n",
            "EVAL: [0/163] Elapsed 0m 0s (remain 2m 12s) Loss: 0.0614(0.0614) \n",
            "EVAL: [20/163] Elapsed 0m 10s (remain 1m 12s) Loss: 0.0646(0.1004) \n",
            "EVAL: [40/163] Elapsed 0m 20s (remain 1m 2s) Loss: 0.0875(0.1043) \n",
            "EVAL: [60/163] Elapsed 0m 32s (remain 0m 54s) Loss: 0.0835(0.1032) \n",
            "EVAL: [80/163] Elapsed 0m 43s (remain 0m 43s) Loss: 0.1090(0.1030) \n",
            "EVAL: [100/163] Elapsed 0m 51s (remain 0m 31s) Loss: 0.0724(0.1061) \n",
            "EVAL: [120/163] Elapsed 1m 1s (remain 0m 21s) Loss: 0.0862(0.1048) \n",
            "EVAL: [140/163] Elapsed 1m 9s (remain 0m 10s) Loss: 0.1015(0.1050) \n",
            "EVAL: [160/163] Elapsed 1m 20s (remain 0m 1s) Loss: 0.1580(0.1053) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0539  avg_val_loss: 0.1051  time: 582s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0539  avg_val_loss: 0.1051  time: 582s\n",
            "Epoch 4 - Score: 0.4591  Scores: [0.4881062537930352, 0.4485787774414766, 0.41794521832162745, 0.4613335013217157, 0.4878704228809679, 0.4509535944509724]\n",
            "INFO:__main__:Epoch 4 - Score: 0.4591  Scores: [0.4881062537930352, 0.4485787774414766, 0.41794521832162745, 0.4613335013217157, 0.4878704228809679, 0.4509535944509724]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [162/163] Elapsed 1m 21s (remain 0m 0s) Loss: 0.0741(0.1051) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 result ==========\n",
            "INFO:__main__:========== fold: 0 result ==========\n",
            "Score: 0.4579  Scores: [0.48462708949956534, 0.447395850682316, 0.41952328993518256, 0.46227964028327867, 0.483915213992011, 0.4494125248458981]\n",
            "INFO:__main__:Score: 0.4579  Scores: [0.48462708949956534, 0.447395850682316, 0.41952328993518256, 0.46227964028327867, 0.483915213992011, 0.4494125248458981]\n",
            "========== fold: 1 training ==========\n",
            "INFO:__main__:========== fold: 1 training ==========\n",
            "DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/978] Elapsed 0m 0s (remain 10m 57s) Loss: 2.5587(2.5587) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][20/978] Elapsed 0m 8s (remain 6m 41s) Loss: 0.9633(0.8823) Grad: 301059.4062  LR: 0.00002000  \n",
            "Epoch: [1][40/978] Elapsed 0m 17s (remain 6m 47s) Loss: 0.3970(0.5750) Grad: 140409.5156  LR: 0.00001999  \n",
            "Epoch: [1][60/978] Elapsed 0m 33s (remain 8m 29s) Loss: 0.0600(0.4618) Grad: 45918.9570  LR: 0.00001999  \n",
            "Epoch: [1][80/978] Elapsed 0m 42s (remain 7m 53s) Loss: 0.1034(0.3934) Grad: 87987.3125  LR: 0.00001998  \n",
            "Epoch: [1][100/978] Elapsed 0m 50s (remain 7m 20s) Loss: 0.1664(0.3466) Grad: 126559.3359  LR: 0.00001997  \n",
            "Epoch: [1][120/978] Elapsed 0m 58s (remain 6m 50s) Loss: 0.1344(0.3110) Grad: 102808.7734  LR: 0.00001995  \n",
            "Epoch: [1][140/978] Elapsed 1m 9s (remain 6m 55s) Loss: 0.1145(0.2911) Grad: 96054.2266  LR: 0.00001994  \n",
            "Epoch: [1][160/978] Elapsed 1m 18s (remain 6m 39s) Loss: 0.1802(0.2750) Grad: 120520.6562  LR: 0.00001992  \n",
            "Epoch: [1][180/978] Elapsed 1m 27s (remain 6m 26s) Loss: 0.3030(0.2644) Grad: 136211.8281  LR: 0.00001989  \n",
            "Epoch: [1][200/978] Elapsed 1m 37s (remain 6m 16s) Loss: 0.1304(0.2535) Grad: 69999.0781  LR: 0.00001987  \n",
            "Epoch: [1][220/978] Elapsed 1m 46s (remain 6m 3s) Loss: 0.1079(0.2422) Grad: 59819.5781  LR: 0.00001984  \n",
            "Epoch: [1][240/978] Elapsed 1m 54s (remain 5m 51s) Loss: 0.1552(0.2367) Grad: 96369.6797  LR: 0.00001981  \n",
            "Epoch: [1][260/978] Elapsed 2m 2s (remain 5m 37s) Loss: 0.0563(0.2286) Grad: 52446.5781  LR: 0.00001978  \n",
            "Epoch: [1][280/978] Elapsed 2m 10s (remain 5m 23s) Loss: 0.1043(0.2233) Grad: 43166.0625  LR: 0.00001975  \n",
            "Epoch: [1][300/978] Elapsed 2m 18s (remain 5m 11s) Loss: 0.1509(0.2164) Grad: 102208.5312  LR: 0.00001971  \n",
            "Epoch: [1][320/978] Elapsed 2m 26s (remain 4m 59s) Loss: 0.1062(0.2114) Grad: 85502.7969  LR: 0.00001967  \n",
            "Epoch: [1][340/978] Elapsed 2m 33s (remain 4m 47s) Loss: 0.1121(0.2066) Grad: 72731.4609  LR: 0.00001963  \n",
            "Epoch: [1][360/978] Elapsed 2m 43s (remain 4m 39s) Loss: 0.1253(0.2029) Grad: 81721.9531  LR: 0.00001958  \n",
            "Epoch: [1][380/978] Elapsed 2m 51s (remain 4m 28s) Loss: 0.0752(0.1988) Grad: 57371.5430  LR: 0.00001954  \n",
            "Epoch: [1][400/978] Elapsed 3m 10s (remain 4m 33s) Loss: 0.3618(0.1969) Grad: 154008.9844  LR: 0.00001949  \n",
            "Epoch: [1][420/978] Elapsed 3m 20s (remain 4m 24s) Loss: 0.1782(0.1948) Grad: 79649.3047  LR: 0.00001943  \n",
            "Epoch: [1][440/978] Elapsed 3m 29s (remain 4m 15s) Loss: 0.0671(0.1954) Grad: 41802.5938  LR: 0.00001938  \n",
            "Epoch: [1][460/978] Elapsed 3m 37s (remain 4m 4s) Loss: 0.1390(0.1936) Grad: 76272.5000  LR: 0.00001932  \n",
            "Epoch: [1][480/978] Elapsed 3m 46s (remain 3m 53s) Loss: 0.0521(0.1907) Grad: 41752.3047  LR: 0.00001926  \n",
            "Epoch: [1][500/978] Elapsed 3m 58s (remain 3m 46s) Loss: 0.0624(0.1877) Grad: 54846.9844  LR: 0.00001920  \n",
            "Epoch: [1][520/978] Elapsed 4m 11s (remain 3m 41s) Loss: 0.0446(0.1847) Grad: 35582.9688  LR: 0.00001914  \n",
            "Epoch: [1][540/978] Elapsed 4m 32s (remain 3m 40s) Loss: 0.1233(0.1836) Grad: 72919.3672  LR: 0.00001907  \n",
            "Epoch: [1][560/978] Elapsed 4m 41s (remain 3m 28s) Loss: 0.2188(0.1817) Grad: 110082.9766  LR: 0.00001900  \n",
            "Epoch: [1][580/978] Elapsed 4m 49s (remain 3m 18s) Loss: 0.1085(0.1807) Grad: 65965.9219  LR: 0.00001893  \n",
            "Epoch: [1][600/978] Elapsed 5m 0s (remain 3m 8s) Loss: 0.0984(0.1799) Grad: 68493.5859  LR: 0.00001886  \n",
            "Epoch: [1][620/978] Elapsed 5m 11s (remain 2m 59s) Loss: 0.0884(0.1784) Grad: 64022.4844  LR: 0.00001878  \n",
            "Epoch: [1][640/978] Elapsed 5m 22s (remain 2m 49s) Loss: 0.4275(0.1779) Grad: 132182.2656  LR: 0.00001870  \n",
            "Epoch: [1][660/978] Elapsed 5m 33s (remain 2m 39s) Loss: 0.3729(0.1770) Grad: 81322.0391  LR: 0.00001862  \n",
            "Epoch: [1][680/978] Elapsed 5m 44s (remain 2m 30s) Loss: 0.2217(0.1760) Grad: 129239.0859  LR: 0.00001854  \n",
            "Epoch: [1][700/978] Elapsed 5m 54s (remain 2m 20s) Loss: 0.1020(0.1740) Grad: 50952.5000  LR: 0.00001846  \n",
            "Epoch: [1][720/978] Elapsed 6m 2s (remain 2m 9s) Loss: 0.2479(0.1725) Grad: 71356.8984  LR: 0.00001837  \n",
            "Epoch: [1][740/978] Elapsed 6m 12s (remain 1m 59s) Loss: 0.1776(0.1725) Grad: 43475.6758  LR: 0.00001828  \n",
            "Epoch: [1][760/978] Elapsed 6m 20s (remain 1m 48s) Loss: 0.1122(0.1711) Grad: 80290.8203  LR: 0.00001819  \n",
            "Epoch: [1][780/978] Elapsed 6m 28s (remain 1m 37s) Loss: 0.2492(0.1701) Grad: 88936.0391  LR: 0.00001810  \n",
            "Epoch: [1][800/978] Elapsed 6m 37s (remain 1m 27s) Loss: 0.0999(0.1697) Grad: 60082.1680  LR: 0.00001800  \n",
            "Epoch: [1][820/978] Elapsed 6m 45s (remain 1m 17s) Loss: 0.0724(0.1683) Grad: 59164.7500  LR: 0.00001790  \n",
            "Epoch: [1][840/978] Elapsed 6m 54s (remain 1m 7s) Loss: 0.1543(0.1671) Grad: 49036.3359  LR: 0.00001780  \n",
            "Epoch: [1][860/978] Elapsed 7m 3s (remain 0m 57s) Loss: 0.1438(0.1659) Grad: 77257.6641  LR: 0.00001770  \n",
            "Epoch: [1][880/978] Elapsed 7m 12s (remain 0m 47s) Loss: 0.0903(0.1653) Grad: 30850.2734  LR: 0.00001760  \n",
            "Epoch: [1][900/978] Elapsed 7m 23s (remain 0m 37s) Loss: 0.1095(0.1641) Grad: 61831.8828  LR: 0.00001749  \n",
            "Epoch: [1][920/978] Elapsed 7m 35s (remain 0m 28s) Loss: 0.0435(0.1634) Grad: 43063.9609  LR: 0.00001739  \n",
            "Epoch: [1][940/978] Elapsed 7m 44s (remain 0m 18s) Loss: 0.2366(0.1629) Grad: 111198.5938  LR: 0.00001728  \n",
            "Epoch: [1][960/978] Elapsed 8m 5s (remain 0m 8s) Loss: 0.0414(0.1622) Grad: 37091.1758  LR: 0.00001717  \n",
            "Epoch: [1][977/978] Elapsed 8m 11s (remain 0m 0s) Loss: 0.1136(0.1625) Grad: 46761.3398  LR: 0.00001707  \n",
            "EVAL: [0/163] Elapsed 0m 0s (remain 1m 44s) Loss: 0.1233(0.1233) \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-da72debb0f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-202cb188f4f2>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6ae2f4272229>\u001b[0m in \u001b[0;36mvalid_fn\u001b[0;34m(valid_loader, model, criterion, device)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-80218b3b6597>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-80218b3b6597>\u001b[0m in \u001b[0;36mfeature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m         )\n\u001b[1;32m   1006\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m                 )\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         )\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mrel_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisentangled_att_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrel_att\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mdisentangled_att_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mp2c_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_query_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             p2c_att = torch.gather(\n\u001b[0;32m--> 747\u001b[0;31m                 \u001b[0mp2c_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2c_dynamic_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2c_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m             ).transpose(-1, -2)\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.25 GiB (GPU 0; 39.59 GiB total capacity; 27.60 GiB already allocated; 4.04 GiB free; 34.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    \n",
        "    def get_result(oof_df):\n",
        "        labels = oof_df[CFG.target_cols].values\n",
        "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
        "        score, scores = get_score(labels, preds)\n",
        "        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
        "    \n",
        "    if CFG.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(CFG.n_fold):\n",
        "            if fold in CFG.trn_fold:\n",
        "                _oof_df = train_loop(train, fold)\n",
        "                oof_df = pd.concat([oof_df, _oof_df])\n",
        "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "                get_result(_oof_df)\n",
        "        oof_df = oof_df.reset_index(drop=True)\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
        "        \n",
        "    if CFG.wandb:\n",
        "        wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12032.949787,
      "end_time": "2022-09-01T01:51:45.270554",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-31T22:31:12.320767",
      "version": "2.3.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b28978f614ed44cea929d43958cfb805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_334322315b2949628a1f4e6bfe8eaa6d",
              "IPY_MODEL_857acd52273645c79b1dc3ea4fe5ebed",
              "IPY_MODEL_0ae0a453e2be4939a3af61578ba7e75e"
            ],
            "layout": "IPY_MODEL_20e4aec2306b4b34828af01aee0747d1"
          }
        },
        "334322315b2949628a1f4e6bfe8eaa6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d52505015994435a45bd969e29ffaee",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd28b3cd9c4499cb420aa2031edb1b5",
            "value": "100%"
          }
        },
        "857acd52273645c79b1dc3ea4fe5ebed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a345159ab4481f9b0608bca70019f6",
            "max": 3911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2c9a86bd5344d65b6b81f5bd52a8bd7",
            "value": 3911
          }
        },
        "0ae0a453e2be4939a3af61578ba7e75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbe63369fcf4ebaa78f7ac0bd04e47b",
            "placeholder": "​",
            "style": "IPY_MODEL_63c4dac9124f48678a7a3d10d636cdb0",
            "value": " 3911/3911 [00:04&lt;00:00, 995.99it/s]"
          }
        },
        "20e4aec2306b4b34828af01aee0747d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d52505015994435a45bd969e29ffaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd28b3cd9c4499cb420aa2031edb1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a345159ab4481f9b0608bca70019f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c9a86bd5344d65b6b81f5bd52a8bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bbe63369fcf4ebaa78f7ac0bd04e47b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c4dac9124f48678a7a3d10d636cdb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}