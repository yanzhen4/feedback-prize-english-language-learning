{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanzhen4/feedback-prize-english-language-learning/blob/master/DeBERTa-pseudoLabel%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4487dd87",
      "metadata": {
        "papermill": {
          "duration": 0.006995,
          "end_time": "2022-08-31T22:31:20.199821",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.192826",
          "status": "completed"
        },
        "tags": [],
        "id": "4487dd87"
      },
      "source": [
        "# About this notebook\n",
        "- Deberta-v3-base starter code\n",
        "- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/fb3-pip-wheels)\n",
        "- Inference notebook is [here](https://www.kaggle.com/yasufuminakama/fb3-deberta-v3-base-baseline-inference)\n",
        "\n",
        "If this notebook is helpful, feel free to upvote :)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Package: pip install wandb transformers tokenizers iterative-stratification"
      ],
      "metadata": {
        "id": "J5uY3toQO9es"
      },
      "id": "J5uY3toQO9es"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9f89e5f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.233612Z",
          "iopub.status.busy": "2022-08-31T22:31:20.233146Z",
          "iopub.status.idle": "2022-08-31T22:31:20.248183Z",
          "shell.execute_reply": "2022-08-31T22:31:20.247226Z"
        },
        "papermill": {
          "duration": 0.027843,
          "end_time": "2022-08-31T22:31:20.251266",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.223423",
          "status": "completed"
        },
        "tags": [],
        "id": "9f89e5f8"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = '/content/gdrive/MyDrive/Colab_Notebooks/Deberta/'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00af3d33",
      "metadata": {
        "papermill": {
          "duration": 0.006899,
          "end_time": "2022-08-31T22:31:20.215491",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.208592",
          "status": "completed"
        },
        "tags": [],
        "id": "00af3d33"
      },
      "source": [
        "# Directory settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvhPIWIZOA9T",
        "outputId": "4e3c6330-536c-4036-af24-09ed538b94c6"
      },
      "id": "FvhPIWIZOA9T",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b42ab58",
      "metadata": {
        "papermill": {
          "duration": 0.00523,
          "end_time": "2022-08-31T22:31:20.262025",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.256795",
          "status": "completed"
        },
        "tags": [],
        "id": "8b42ab58"
      },
      "source": [
        "# CFG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e5d62d96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.275246Z",
          "iopub.status.busy": "2022-08-31T22:31:20.274550Z",
          "iopub.status.idle": "2022-08-31T22:31:20.282480Z",
          "shell.execute_reply": "2022-08-31T22:31:20.281625Z"
        },
        "papermill": {
          "duration": 0.01687,
          "end_time": "2022-08-31T22:31:20.284537",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.267667",
          "status": "completed"
        },
        "tags": [],
        "id": "e5d62d96"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    wandb=True\n",
        "    competition='FB3'\n",
        "    _wandb_kernel='nakama'\n",
        "    debug=False\n",
        "    apex=True\n",
        "    print_freq=20\n",
        "    num_workers=4\n",
        "    model=\"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\"\n",
        "    gradient_checkpointing=True\n",
        "    scheduler='cosine' # ['linear', 'cosine']\n",
        "    batch_scheduler=True\n",
        "    num_cycles=0.5\n",
        "    num_warmup_steps=0\n",
        "    epochs=5\n",
        "    encoder_lr=2e-5\n",
        "    decoder_lr=2e-5\n",
        "    min_lr=1e-6\n",
        "    eps=1e-6\n",
        "    betas=(0.9, 0.999)\n",
        "    batch_size=1\n",
        "    max_len=512\n",
        "    weight_decay=0.01\n",
        "    gradient_accumulation_steps=1\n",
        "    max_grad_norm=1000\n",
        "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "    seed=42\n",
        "    n_fold=4\n",
        "    trn_fold=[0, 1, 2, 3]\n",
        "    train=True\n",
        "    \n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4692bb04",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:20.297610Z",
          "iopub.status.busy": "2022-08-31T22:31:20.296833Z",
          "iopub.status.idle": "2022-08-31T22:31:29.392500Z",
          "shell.execute_reply": "2022-08-31T22:31:29.391447Z"
        },
        "papermill": {
          "duration": 9.105575,
          "end_time": "2022-08-31T22:31:29.395630",
          "exception": false,
          "start_time": "2022-08-31T22:31:20.290055",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "4692bb04",
        "outputId": "742ce72c-a299-446a-88fb-58f55b985ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
            "Get your W&B access token from here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1g83du8a) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] loss</td><td>█▂▂▂▂▁▂▁▂▁▂▂▁▁▂▂▁▁▁▂▁▂▁▂▂▂▂▂▂▁▁▁▂▁▂▂▁▂▁▂</td></tr><tr><td>[fold0] lr</td><td>███████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] loss</td><td>0.12919</td></tr><tr><td>[fold0] lr</td><td>2e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large</strong>: <a href=\"https://wandb.ai/yanzhen4/FB3-Public/runs/1g83du8a\" target=\"_blank\">https://wandb.ai/yanzhen4/FB3-Public/runs/1g83du8a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221125_000742-1g83du8a/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1g83du8a). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221125_001122-22tyan8a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/yanzhen4/FB3-Public/runs/22tyan8a\" target=\"_blank\">/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large</a></strong> to <a href=\"https://wandb.ai/yanzhen4/FB3-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ====================================================\n",
        "# wandb\n",
        "# ====================================================\n",
        "if CFG.wandb:\n",
        "    \n",
        "    import wandb\n",
        "\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
        "        wandb.login(key=secret_value_0)\n",
        "        anony = None\n",
        "    except:\n",
        "        anony = \"must\"\n",
        "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
        "\n",
        "\n",
        "    def class2dict(f):\n",
        "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
        "\n",
        "    run = wandb.init(project='FB3-Public', \n",
        "                     name=CFG.model,\n",
        "                     config=class2dict(CFG),\n",
        "                     group=CFG.model,\n",
        "                     job_type=\"train\",\n",
        "                     anonymous=anony)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59ce0b2",
      "metadata": {
        "papermill": {
          "duration": 0.009322,
          "end_time": "2022-08-31T22:31:29.415506",
          "exception": false,
          "start_time": "2022-08-31T22:31:29.406184",
          "status": "completed"
        },
        "tags": [],
        "id": "b59ce0b2"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f513d712",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:31:29.436467Z",
          "iopub.status.busy": "2022-08-31T22:31:29.436018Z",
          "iopub.status.idle": "2022-08-31T22:32:28.081444Z",
          "shell.execute_reply": "2022-08-31T22:32:28.080370Z"
        },
        "papermill": {
          "duration": 58.659308,
          "end_time": "2022-08-31T22:32:28.084435",
          "exception": false,
          "start_time": "2022-08-31T22:31:29.425127",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f513d712",
        "outputId": "f8a81f6e-9617-47de-cb61-372f96b0eef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers.__version__: 4.24.0\n"
          ]
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "#os.system('pip install iterative-stratification==0.1.7')\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#os.system('pip uninstall -y transformers')\n",
        "#os.system('pip uninstall -y tokenizers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels transformers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels tokenizers')\n",
        "#import tokenizers\n",
        "import transformers\n",
        "#print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "#%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c521bb35",
      "metadata": {
        "papermill": {
          "duration": 0.015189,
          "end_time": "2022-08-31T22:32:28.113643",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.098454",
          "status": "completed"
        },
        "tags": [],
        "id": "c521bb35"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "37e2a622",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.142081Z",
          "iopub.status.busy": "2022-08-31T22:32:28.140999Z",
          "iopub.status.idle": "2022-08-31T22:32:28.163185Z",
          "shell.execute_reply": "2022-08-31T22:32:28.162199Z"
        },
        "papermill": {
          "duration": 0.039148,
          "end_time": "2022-08-31T22:32:28.165976",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.126828",
          "status": "completed"
        },
        "tags": [],
        "id": "37e2a622"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "def MCRMSE(y_trues, y_preds): #loss\n",
        "    scores = []\n",
        "    idxes = y_trues.shape[1]\n",
        "    for i in range(idxes):\n",
        "        y_true = y_trues[:,i]\n",
        "        y_pred = y_preds[:,i]\n",
        "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
        "        scores.append(score)\n",
        "    mcrmse_score = np.mean(scores)\n",
        "    return mcrmse_score, scores #score: single prediction result; scores: list of all results\n",
        "\n",
        "\n",
        "def get_score(y_trues, y_preds):\n",
        "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
        "    return mcrmse_score, scores\n",
        "\n",
        "\n",
        "def get_logger(filename=OUTPUT_DIR+'train'): #print log \n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e95c84",
      "metadata": {
        "papermill": {
          "duration": 0.010764,
          "end_time": "2022-08-31T22:32:28.191852",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.181088",
          "status": "completed"
        },
        "tags": [],
        "id": "94e95c84"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Data Loading\n",
        "# ====================================================\n",
        "train = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/train.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/test.csv')\n",
        "submission = pd.read_csv('/content/gdrive/MyDrive/Colab_Notebooks/Deberta/sample_submission.csv')\n",
        "old_train = pd.read_csv(\"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/old_train.csv\")"
      ],
      "metadata": {
        "id": "iYFCrZKIIXbV"
      },
      "id": "iYFCrZKIIXbV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "db454733",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.216397Z",
          "iopub.status.busy": "2022-08-31T22:32:28.215550Z",
          "iopub.status.idle": "2022-08-31T22:32:28.504765Z",
          "shell.execute_reply": "2022-08-31T22:32:28.503570Z"
        },
        "papermill": {
          "duration": 0.304959,
          "end_time": "2022-08-31T22:32:28.508101",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.203142",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "db454733",
        "outputId": "21ea953c-1aae-49b6-a6ac-fc9645716b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (1000, 8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0d07795-bc3a-415a-a0fe-1b22765d1b9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d07795-bc3a-415a-a0fe-1b22765d1b9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0d07795-bc3a-415a-a0fe-1b22765d1b9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0d07795-bc3a-415a-a0fe-1b22765d1b9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.shape: (3, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id                                          full_text\n",
              "0  0000C359D63E  when a person has no experience on a job their...\n",
              "1  000BAD50D026  Do you think students would benefit from being...\n",
              "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c60b3cd-a025-4ead-9b53-f776c739ebd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>when a person has no experience on a job their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>Do you think students would benefit from being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c60b3cd-a025-4ead-9b53-f776c739ebd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c60b3cd-a025-4ead-9b53-f776c739ebd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c60b3cd-a025-4ead-9b53-f776c739ebd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.shape: (3, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0  0000C359D63E       3.0     3.0         3.0          3.0      3.0          3.0\n",
              "1  000BAD50D026       3.0     3.0         3.0          3.0      3.0          3.0\n",
              "2  00367BB2546B       3.0     3.0         3.0          3.0      3.0          3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26c658f1-bc3c-4bed-9622-d6d50899f7a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26c658f1-bc3c-4bed-9622-d6d50899f7a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26c658f1-bc3c-4bed-9622-d6d50899f7a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26c658f1-bc3c-4bed-9622-d6d50899f7a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Test\n",
        "train = train.head(1000)\n",
        "print(f\"train.shape: {train.shape}\")\n",
        "display(train.head())\n",
        "print(f\"test.shape: {test.shape}\")\n",
        "display(test.head())\n",
        "print(f\"submission.shape: {submission.shape}\")\n",
        "display(submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = 100\n",
        "old_train = old_train[[\"discourse_text\"]].rename(columns={\"discourse_text\": \"full_text\"})\n",
        "old_train = old_train[old_train[\"full_text\"].str.len() >= 500].head(size).reset_index()\n",
        "old_train = old_train.drop(columns = ['index'])\n",
        "initial_values = np.zeros((len(old_train), 6))\n",
        "old_train[CFG.target_cols] = initial_values\n",
        "old_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bAmBrAta0HA-",
        "outputId": "78fe4803-7160-4e18-a6c6-09723e042446"
      },
      "id": "bAmBrAta0HA-",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0   According to an article by the Edgar Snyder Fi...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "1   The most common of these distractions is a cel...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "2   Reaction time is the measure of how quickly an...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "3   The affects can be physical, emotional, or psy...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "4   In conclusion, people shouldn't use cellphones...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "5   It could lead to accidents and altercations. Y...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "6   Many people happen to pass away due to a motor...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "7   In conclusion, Drivers shouldn't drive while u...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "8   Other drivers take notice when drivers are on ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "9   Driving with cell phones should be banned beca...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "10  Statistically, 50 minutes of phone chatter whi...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "11  Cell phones were presented within the United S...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "12  Drivers who are distracted by their phone whil...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "13  Distracted driving is now considered to be the...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "14  Reasons for this can range from work related t...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "15  The question is people more concerned more wit...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "16  A major cause of deaths in the US is motor veh...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "17  According to an article of \" Teen driver sourc...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "18  Each state in the US has their own laws to pro...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "19  While physical damage to a vehicle or physical...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "20  According to the website big AZ BIG Media, the...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "21  Although cell phones have not been around for ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "22  Throughout the years, teenagers have been eage...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "23  Utilizing a phone while driving takes many liv...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "24  Once again, using a phone while driving create...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "25  The new law was put in to ensure more safety d...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "26  A phone should not ever be used while a person...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "27  There are just so many things that we are able...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "28   If you are at a red light and you don't have ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "29  Now with these cars we don't need to worry abo...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "30  It's said that only 39 states put a ban for no...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "31  I think I could say the same thing for a passe...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "32  When using your phone while driving, you shoul...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "33  In today's day and age, technology has drastic...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "34  When you make the decision to text and drive, ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "35  Regardless of the all the harm caused by texti...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "36   In 2018 half a million people were injured be...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "37  In an article \"Just how much does car insuranc...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "38  There are 41 state that ban texting while driv...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "39  The use of cars and mobile technology has done...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "40  Drivers often use their phones for GPS in this...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "41   Although texting and driving is the cause of ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "42  According to Legalmatch \"Texting while driving...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "43  In Conclusion, Drivers should not be able to u...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "44  You're driving in your car so someone who you ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "45  On busy roads, the amount of time that one tal...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "46  94% percent of drivers support a ban on textin...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "47  On one occasion, my mom was hit from behind be...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "48  My mom's car insurance increased an additional...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "49  Everybody has their own opinion regarding cell...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "50  It doesn't matter where you are you turn your ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "51   There have been many different accidents beca...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "52  There is always pros and cons about things peo...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "53  If an emergency maneuver or emergency braking ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "54  Ever since phones have entered into the world,...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "55  \"Sending or reading a text causes drivers, on ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "56  When people use their cell phones on the highw...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "57  Why is this? It is because using a cell phone ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "58  even if the driver only looked at the phone ju...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "59  \"Drivers on the phone have worse reaction time...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "60  As the driver you not only risk your own life,...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "61  Cell phone use should be prohibited why you op...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "62  Talking while driving isn't as bad because you...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "63  The National Safety Council reports that cellp...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "64   In society, money is tight when it comes to d...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "65  Distractive driving effects all drivers equall...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "66  It is important to know because the bad behavi...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "67  The driver will also experience a physical dis...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "68  You make decisions to text and drive, you make...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "69  Reasoning on no devices while driving is part ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "70  When you choose to text and drive, you're thre...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "71  You get pulled over and get a ticket. But also...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "72  Being able to use a device while operating a v...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "73  At least one out of every twenty drivers will ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "74   Amongst accidents, an average of nine teens a...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "75  On Instamotor it discusses 5 best gadgets to c...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "76  Another useful gadget is called the \"Motorola ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "77  Texting while driving is one of the worrying t...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "78  Despite these consequences, people are still f...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "79  On the other hand, these news laws need to ban...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "80  I strongly agree that texting and driving is t...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "81  Phones play a key role in people keeping in to...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "82  For instance, accidents caused by cellphone us...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "83  In my final judgment, I suppose we can drive s...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "84  The reason why people are using their phones w...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "85  Is it really that important? A text is not mor...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "86  The number of fatal crashes caused by cell pho...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "87  Teenagers are not as experienced drivers and t...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "88  So even if you are using your phone and paying...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "89  Studies have shown that while talking to someo...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "90  Andrei Zakhareuski, from Driving Tests, procla...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "91  Cells phones are very common place for everyon...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "92  In fact adults are put at a higher risk becaus...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "93  Many people use their cell phones while drivin...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "94  Driving while operating your phone can end in ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "95  If not, put down the phone and wait until you ...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "96  Among those killed: 1,730 drivers, 605 passeng...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "97  This shows that the couple of seconds you take...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "98  \\nCell phones were introduced in the United St...       0.0     0.0         0.0          0.0      0.0          0.0\n",
              "99  Researches show that using a headset can be as...       0.0     0.0         0.0          0.0      0.0          0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-373fe043-916c-4a29-b3f4-3788b2415bd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to an article by the Edgar Snyder Fi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The most common of these distractions is a cel...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Reaction time is the measure of how quickly an...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The affects can be physical, emotional, or psy...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In conclusion, people shouldn't use cellphones...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It could lead to accidents and altercations. Y...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Many people happen to pass away due to a motor...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In conclusion, Drivers shouldn't drive while u...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Other drivers take notice when drivers are on ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Driving with cell phones should be banned beca...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Statistically, 50 minutes of phone chatter whi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Cell phones were presented within the United S...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Drivers who are distracted by their phone whil...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Distracted driving is now considered to be the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Reasons for this can range from work related t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The question is people more concerned more wit...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>A major cause of deaths in the US is motor veh...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>According to an article of \" Teen driver sourc...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Each state in the US has their own laws to pro...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>While physical damage to a vehicle or physical...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>According to the website big AZ BIG Media, the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Although cell phones have not been around for ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Throughout the years, teenagers have been eage...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Utilizing a phone while driving takes many liv...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Once again, using a phone while driving create...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>The new law was put in to ensure more safety d...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>A phone should not ever be used while a person...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>There are just so many things that we are able...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>If you are at a red light and you don't have ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Now with these cars we don't need to worry abo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>It's said that only 39 states put a ban for no...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I think I could say the same thing for a passe...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>When using your phone while driving, you shoul...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>In today's day and age, technology has drastic...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>When you make the decision to text and drive, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Regardless of the all the harm caused by texti...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>In 2018 half a million people were injured be...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>In an article \"Just how much does car insuranc...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>There are 41 state that ban texting while driv...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>The use of cars and mobile technology has done...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Drivers often use their phones for GPS in this...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Although texting and driving is the cause of ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>According to Legalmatch \"Texting while driving...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>In Conclusion, Drivers should not be able to u...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>You're driving in your car so someone who you ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>On busy roads, the amount of time that one tal...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>94% percent of drivers support a ban on textin...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>On one occasion, my mom was hit from behind be...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>My mom's car insurance increased an additional...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Everybody has their own opinion regarding cell...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>It doesn't matter where you are you turn your ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>There have been many different accidents beca...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>There is always pros and cons about things peo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>If an emergency maneuver or emergency braking ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Ever since phones have entered into the world,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>\"Sending or reading a text causes drivers, on ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>When people use their cell phones on the highw...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Why is this? It is because using a cell phone ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>even if the driver only looked at the phone ju...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>\"Drivers on the phone have worse reaction time...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>As the driver you not only risk your own life,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Cell phone use should be prohibited why you op...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Talking while driving isn't as bad because you...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>The National Safety Council reports that cellp...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>In society, money is tight when it comes to d...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Distractive driving effects all drivers equall...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>It is important to know because the bad behavi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>The driver will also experience a physical dis...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>You make decisions to text and drive, you make...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Reasoning on no devices while driving is part ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>When you choose to text and drive, you're thre...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>You get pulled over and get a ticket. But also...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Being able to use a device while operating a v...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>At least one out of every twenty drivers will ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Amongst accidents, an average of nine teens a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>On Instamotor it discusses 5 best gadgets to c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Another useful gadget is called the \"Motorola ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Texting while driving is one of the worrying t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Despite these consequences, people are still f...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>On the other hand, these news laws need to ban...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>I strongly agree that texting and driving is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Phones play a key role in people keeping in to...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>For instance, accidents caused by cellphone us...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>In my final judgment, I suppose we can drive s...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>The reason why people are using their phones w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Is it really that important? A text is not mor...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>The number of fatal crashes caused by cell pho...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Teenagers are not as experienced drivers and t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>So even if you are using your phone and paying...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Studies have shown that while talking to someo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Andrei Zakhareuski, from Driving Tests, procla...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Cells phones are very common place for everyon...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>In fact adults are put at a higher risk becaus...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Many people use their cell phones while drivin...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Driving while operating your phone can end in ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>If not, put down the phone and wait until you ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Among those killed: 1,730 drivers, 605 passeng...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>This shows that the couple of seconds you take...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>\\nCell phones were introduced in the United St...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Researches show that using a headset can be as...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-373fe043-916c-4a29-b3f4-3788b2415bd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-373fe043-916c-4a29-b3f4-3788b2415bd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-373fe043-916c-4a29-b3f4-3788b2415bd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae4a81b",
      "metadata": {
        "papermill": {
          "duration": 0.009487,
          "end_time": "2022-08-31T22:32:28.527661",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.518174",
          "status": "completed"
        },
        "tags": [],
        "id": "dae4a81b"
      },
      "source": [
        "# CV split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "32200ebe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.554307Z",
          "iopub.status.busy": "2022-08-31T22:32:28.553699Z",
          "iopub.status.idle": "2022-08-31T22:32:28.704323Z",
          "shell.execute_reply": "2022-08-31T22:32:28.703340Z"
        },
        "papermill": {
          "duration": 0.164445,
          "end_time": "2022-08-31T22:32:28.706697",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.542252",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "32200ebe",
        "outputId": "5f02f9a0-aab0-4cbf-eabd-e9d34cd27312"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0    250\n",
              "1    250\n",
              "2    250\n",
              "3    250\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ====================================================\n",
        "# CV split\n",
        "# ====================================================\n",
        "Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n",
        "    train.loc[val_index, 'fold'] = int(n)\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "display(train.groupby('fold').size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R33CkEsSpEu",
        "outputId": "196f7972-af6f-4221-ef2b-48356f525922"
      },
      "id": "-R33CkEsSpEu",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a025258f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.724353Z",
          "iopub.status.busy": "2022-08-31T22:32:28.724052Z",
          "iopub.status.idle": "2022-08-31T22:32:28.729744Z",
          "shell.execute_reply": "2022-08-31T22:32:28.728851Z"
        },
        "papermill": {
          "duration": 0.016964,
          "end_time": "2022-08-31T22:32:28.731888",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.714924",
          "status": "completed"
        },
        "tags": [],
        "id": "a025258f"
      },
      "outputs": [],
      "source": [
        "if CFG.debug:\n",
        "    display(train.groupby('fold').size())\n",
        "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
        "    display(train.groupby('fold').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2d766a",
      "metadata": {
        "papermill": {
          "duration": 0.007793,
          "end_time": "2022-08-31T22:32:28.747828",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.740035",
          "status": "completed"
        },
        "tags": [],
        "id": "aa2d766a"
      },
      "source": [
        "# tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d2fa845d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:28.765839Z",
          "iopub.status.busy": "2022-08-31T22:32:28.765473Z",
          "iopub.status.idle": "2022-08-31T22:32:35.437418Z",
          "shell.execute_reply": "2022-08-31T22:32:35.436468Z"
        },
        "papermill": {
          "duration": 6.683936,
          "end_time": "2022-08-31T22:32:35.439931",
          "exception": false,
          "start_time": "2022-08-31T22:32:28.755995",
          "status": "completed"
        },
        "tags": [],
        "id": "d2fa845d"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# tokenizer\n",
        "# ====================================================\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model) #get deberta tokenizer \n",
        "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
        "CFG.tokenizer = tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df117510",
      "metadata": {
        "papermill": {
          "duration": 0.008087,
          "end_time": "2022-08-31T22:32:35.456694",
          "exception": false,
          "start_time": "2022-08-31T22:32:35.448607",
          "status": "completed"
        },
        "tags": [],
        "id": "df117510"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "dac78bb9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:35.476349Z",
          "iopub.status.busy": "2022-08-31T22:32:35.475302Z",
          "iopub.status.idle": "2022-08-31T22:32:41.683449Z",
          "shell.execute_reply": "2022-08-31T22:32:41.681990Z"
        },
        "papermill": {
          "duration": 6.221034,
          "end_time": "2022-08-31T22:32:41.686006",
          "exception": false,
          "start_time": "2022-08-31T22:32:35.464972",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5bffe53251994c9ca153202549dd5852",
            "e0203391c176486e8048d44856a830de",
            "235e946c72034a83b29b138306dc2d1c",
            "0888665440984b9a8f6bcb71ad7bae12",
            "88cea0eccd7d46c69481218a8f22ac3d",
            "e621c5ebcbf848e8a7d4b0fa8da0371d",
            "41c28c954af14d9a9375ae74a81e4216",
            "69b087ad208e43b2af30ada54f9a7171",
            "dd73281739dc4d3fbf1ecff719028cd4",
            "f6658d500599423e967cff396a18c9df",
            "17eb52cf493b479e8a747e98ee116d80"
          ]
        },
        "id": "dac78bb9",
        "outputId": "5d798718-ea71-462b-85c5-edbbd470bfe9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bffe53251994c9ca153202549dd5852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "max_len: 4182\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1029, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1009, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
            "    runner = Runner(result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 714, in __init__\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
            "    user_expressions, allow_stdin,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
            "    raw_cell, store_history, silent, shell_futures)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-34-7acbe140ac57>\", line 11, in <module>\n",
            "    LOGGER.info(f\"max_len: {CFG.max_len}\")\n",
            "Message: 'max_len: 4182'\n",
            "Arguments: ()\n",
            "max_len: 4182\n",
            "INFO:__main__:max_len: 4182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4182"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Define max_len\n",
        "# Find max token length after tokenizing each text \n",
        "# ====================================================\n",
        "lengths = []\n",
        "tk0 = tqdm(train['full_text'].fillna(\"\").values, total=len(train))\n",
        "for text in tk0:\n",
        "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "CFG.max_len = max(lengths) + 3 # cls & sep & sep\n",
        "LOGGER.info(f\"max_len: {CFG.max_len}\")\n",
        "CFG.max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "14b26230",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.706635Z",
          "iopub.status.busy": "2022-08-31T22:32:41.704899Z",
          "iopub.status.idle": "2022-08-31T22:32:41.715654Z",
          "shell.execute_reply": "2022-08-31T22:32:41.714775Z"
        },
        "papermill": {
          "duration": 0.022792,
          "end_time": "2022-08-31T22:32:41.717965",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.695173",
          "status": "completed"
        },
        "tags": [],
        "id": "14b26230"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Dataset\n",
        "# ====================================================\n",
        "def prepare_input(cfg, text):\n",
        "    inputs = cfg.tokenizer.encode_plus(\n",
        "        text, \n",
        "        return_tensors=None, \n",
        "        add_special_tokens=True, \n",
        "        max_length=CFG.max_len,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True\n",
        "    )\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "    return inputs #a list of tensors \n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, cfg, df):\n",
        "        self.cfg = cfg\n",
        "        self.texts = df['full_text'].values\n",
        "        self.labels = df[cfg.target_cols].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = prepare_input(self.cfg, self.texts[item])\n",
        "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
        "        return inputs, label\n",
        "    \n",
        "\n",
        "def collate(inputs):\n",
        "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:,:mask_len]\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bda5663",
      "metadata": {
        "papermill": {
          "duration": 0.008337,
          "end_time": "2022-08-31T22:32:41.734920",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.726583",
          "status": "completed"
        },
        "tags": [],
        "id": "2bda5663"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a5f24525",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.754836Z",
          "iopub.status.busy": "2022-08-31T22:32:41.754449Z",
          "iopub.status.idle": "2022-08-31T22:32:41.773130Z",
          "shell.execute_reply": "2022-08-31T22:32:41.769556Z"
        },
        "papermill": {
          "duration": 0.031877,
          "end_time": "2022-08-31T22:32:41.776126",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.744249",
          "status": "completed"
        },
        "tags": [],
        "id": "a5f24525"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Model\n",
        "# ====================================================\n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float() \n",
        "        #last_hidden_state is a list of n tensors, n is sequence length\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        #padding: [PAD] make same length, for [PAD] attention_mask = 0\n",
        "        #last_hidden_state is output of the model\n",
        "        return mean_embeddings\n",
        "    \n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if config_path is None:\n",
        "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True) \n",
        "            #output of every layer during inference\n",
        "            self.config.hidden_dropout = 0.\n",
        "            self.config.hidden_dropout_prob = 0.\n",
        "            self.config.attention_dropout = 0.\n",
        "            self.config.attention_probs_dropout_prob = 0.\n",
        "            LOGGER.info(self.config)\n",
        "        else:\n",
        "            self.config = torch.load(config_path)\n",
        "        if pretrained:\n",
        "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
        "        else:\n",
        "            self.model = AutoModel(self.config)\n",
        "        if self.cfg.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "        self.pool = MeanPooling()\n",
        "        self.fc = nn.Linear(self.config.hidden_size, 6) #hidden_size is input size, 6 is output size \n",
        "        self._init_weights(self.fc)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        \n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        last_hidden_states = outputs[0]\n",
        "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
        "        return feature\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        output = self.fc(feature)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f90882e",
      "metadata": {
        "papermill": {
          "duration": 0.008836,
          "end_time": "2022-08-31T22:32:41.801081",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.792245",
          "status": "completed"
        },
        "tags": [],
        "id": "3f90882e"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4ffd8144",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.819862Z",
          "iopub.status.busy": "2022-08-31T22:32:41.819486Z",
          "iopub.status.idle": "2022-08-31T22:32:41.829800Z",
          "shell.execute_reply": "2022-08-31T22:32:41.827775Z"
        },
        "papermill": {
          "duration": 0.023124,
          "end_time": "2022-08-31T22:32:41.832806",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.809682",
          "status": "completed"
        },
        "tags": [],
        "id": "4ffd8144"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Loss\n",
        "# ====================================================\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, reduction='mean', eps=1e-9):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction='none')\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
        "        if self.reduction == 'none':\n",
        "            loss = loss\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c15011e",
      "metadata": {
        "papermill": {
          "duration": 0.008528,
          "end_time": "2022-08-31T22:32:41.852306",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.843778",
          "status": "completed"
        },
        "tags": [],
        "id": "1c15011e"
      },
      "source": [
        "# Helpler functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c11acdda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.872384Z",
          "iopub.status.busy": "2022-08-31T22:32:41.872032Z",
          "iopub.status.idle": "2022-08-31T22:32:41.892510Z",
          "shell.execute_reply": "2022-08-31T22:32:41.891247Z"
        },
        "papermill": {
          "duration": 0.034604,
          "end_time": "2022-08-31T22:32:41.895844",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.861240",
          "status": "completed"
        },
        "tags": [],
        "id": "c11acdda"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    losses = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        #optimize\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch+1, step, len(train_loader), \n",
        "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
        "                          loss=losses,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
        "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
        "    return losses.avg\n",
        "\n",
        "\n",
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs) #predict\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss=losses,\n",
        "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "730d838d",
      "metadata": {
        "papermill": {
          "duration": 0.008782,
          "end_time": "2022-08-31T22:32:41.916203",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.907421",
          "status": "completed"
        },
        "tags": [],
        "id": "730d838d"
      },
      "source": [
        "# train loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "# ====================================================\n",
        "# train loop\n",
        "# ====================================================\n",
        "def train_loop(folds, fold): \n",
        "     \n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # loader\n",
        "    # ====================================================\n",
        "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
        "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
        "    valid_labels = valid_folds[CFG.target_cols].values\n",
        "    \n",
        "    train_dataset = TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
        "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
        "    model.to(device)\n",
        "    \n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr, \n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "    \n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "    \n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n",
        "    \n",
        "    best_score = np.inf\n",
        "\n",
        "    # 5 Epoch with origin data\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "         \n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        \n",
        "        # scoring\n",
        "        score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                       f\"[fold{fold}] score\": score})\n",
        "        \n",
        "        if best_score > score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    #unlabled_data = old data\n",
        "    pesudoLabel_data = old_train #dataframe\n",
        "    pesudoLabel_data_len = len(pesudoLabel_data)\n",
        "    sample_size = int(pesudoLabel_data_len / 5)\n",
        "    for i in range(0, 5):\n",
        "        pesudoLabel_data_use = pesudoLabel_data[:sample_size]\n",
        "        pesudoLabel_data = pesudoLabel_data[sample_size:]\n",
        "        #unlabled_data = unlabled_data - sampled_data\n",
        "        pesudo_dataset = TrainDataset(CFG, pesudoLabel_data_use)\n",
        "        pesudo_loader = DataLoader(pesudo_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "        preds = np.array([[]])\n",
        "        start = end = time.time()\n",
        "        i = 0\n",
        "        for step, (inputs, labels) in enumerate(pesudo_loader):\n",
        "            inputs = collate(inputs)\n",
        "            for k, v in inputs.items():\n",
        "                inputs[k] = v.to(device)\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(inputs) #predict\n",
        "            if i != 0:\n",
        "              preds = np.concatenate((preds, y_preds.to('cpu').numpy()), axis = 0)\n",
        "            else:\n",
        "              i = 1\n",
        "              preds = y_preds.to('cpu').numpy()\n",
        "            end = time.time()\n",
        "        \n",
        "        print(np.array(preds).shape, pesudoLabel_data_use.columns)\n",
        "        pesudoLabel_data_use[CFG.target_cols] = preds\n",
        "        print(train_folds.columns)\n",
        "        print(pesudoLabel_data_use.columns)\n",
        "        frames = [train_folds, pesudoLabel_data_use]\n",
        "        train_folds = pd.concat(frames)\n",
        "        train_dataset = TrainDataset(CFG, train_folds)\n",
        "        train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "        # 5 Epochs training with origin data + pseudo-labled data\n",
        "        for epoch in range(CFG.epochs):\n",
        "\n",
        "            \n",
        "                \n",
        "            start_time = time.time()\n",
        "\n",
        "            #predict for all sampled_data, generate labled data\n",
        "            #stack sampled_data on new data\n",
        "            #add to train_loader\n",
        "            \n",
        "            # train\n",
        "            avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "            # eval\n",
        "            avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "            \n",
        "            # scoring\n",
        "            score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
        "            if CFG.wandb:\n",
        "                wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                          f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                          f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                          f\"[fold{fold}] score\": score})\n",
        "            \n",
        "            if best_score > score:\n",
        "                best_score = score\n",
        "                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "                torch.save({'model': model.state_dict(),\n",
        "                            'predictions': predictions},\n",
        "                            OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            \n",
        "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
        "                             map_location=torch.device('cpu'))['predictions']\n",
        "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return valid_folds"
      ],
      "metadata": {
        "id": "qeIFn4hJywBR"
      },
      "id": "qeIFn4hJywBR",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    def get_result(oof_df):\n",
        "        labels = oof_df[CFG.target_cols].values\n",
        "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
        "        score, scores = get_score(labels, preds)\n",
        "        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
        "    \n",
        "    if CFG.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(CFG.n_fold):\n",
        "            if fold in CFG.trn_fold:\n",
        "                _oof_df = train_loop(train, fold)\n",
        "                oof_df = pd.concat([oof_df, _oof_df])\n",
        "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "                get_result(_oof_df)\n",
        "                break\n",
        "        oof_df = oof_df.reset_index(drop=True)\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
        "        \n",
        "    if CFG.wandb:\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BTIYgNBfy88q",
        "outputId": "96d5956c-ca9a-4683-adbb-dd6f58257831"
      },
      "id": "BTIYgNBfy88q",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 training ==========\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1029, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1009, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
            "    runner = Runner(result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 714, in __init__\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
            "    user_expressions, allow_stdin,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
            "    raw_cell, store_history, silent, shell_futures)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-40-d35ddcac0c41>\", line 14, in <module>\n",
            "    _oof_df = train_loop(train, fold)\n",
            "  File \"<ipython-input-39-48527d1f63f5>\", line 7, in train_loop\n",
            "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
            "Message: '========== fold: 0 training =========='\n",
            "Arguments: ()\n",
            "========== fold: 0 training ==========\n",
            "INFO:__main__:========== fold: 0 training ==========\n",
            "DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1029, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1009, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
            "    yield self.process_one()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
            "    runner = Runner(result, future, yielded)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 714, in __init__\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
            "    user_expressions, allow_stdin,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
            "    yielded = next(result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
            "    raw_cell, store_history, silent, shell_futures)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-40-d35ddcac0c41>\", line 14, in <module>\n",
            "    _oof_df = train_loop(train, fold)\n",
            "  File \"<ipython-input-39-48527d1f63f5>\", line 31, in train_loop\n",
            "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
            "  File \"<ipython-input-36-80218b3b6597>\", line 31, in __init__\n",
            "    LOGGER.info(self.config)\n",
            "Message: DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Arguments: ()\n",
            "DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:__main__:DebertaConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/Colab_Notebooks/Deberta/microsoft_deberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/750] Elapsed 0m 0s (remain 6m 21s) Loss: 2.7481(2.7481) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][20/750] Elapsed 0m 6s (remain 3m 33s) Loss: 0.3021(0.8282) Grad: 158472.5938  LR: 0.00002000  \n",
            "Epoch: [1][40/750] Elapsed 0m 11s (remain 3m 21s) Loss: 0.3297(0.5731) Grad: 251774.5469  LR: 0.00001999  \n",
            "Epoch: [1][60/750] Elapsed 0m 17s (remain 3m 16s) Loss: 0.1676(0.4770) Grad: 122921.8516  LR: 0.00001999  \n",
            "Epoch: [1][80/750] Elapsed 0m 23s (remain 3m 10s) Loss: 0.2169(0.4246) Grad: 123256.4531  LR: 0.00001998  \n",
            "Epoch: [1][100/750] Elapsed 0m 28s (remain 3m 4s) Loss: 1.0078(0.3753) Grad: 217122.1406  LR: 0.00001996  \n",
            "Epoch: [1][120/750] Elapsed 0m 34s (remain 3m 1s) Loss: 0.0590(0.3568) Grad: 70364.3750  LR: 0.00001995  \n",
            "Epoch: [1][140/750] Elapsed 0m 40s (remain 2m 56s) Loss: 0.1288(0.3319) Grad: 115030.8594  LR: 0.00001993  \n",
            "Epoch: [1][160/750] Elapsed 0m 47s (remain 2m 52s) Loss: 0.1006(0.3084) Grad: 85268.1016  LR: 0.00001991  \n",
            "Epoch: [1][180/750] Elapsed 0m 52s (remain 2m 46s) Loss: 0.0548(0.2992) Grad: 62306.2734  LR: 0.00001989  \n",
            "Epoch: [1][200/750] Elapsed 0m 58s (remain 2m 39s) Loss: 0.1895(0.2842) Grad: 119233.9766  LR: 0.00001986  \n",
            "Epoch: [1][220/750] Elapsed 1m 4s (remain 2m 33s) Loss: 0.1843(0.2784) Grad: 124162.0234  LR: 0.00001983  \n",
            "Epoch: [1][240/750] Elapsed 1m 9s (remain 2m 27s) Loss: 0.1173(0.2752) Grad: 90199.0547  LR: 0.00001980  \n",
            "Epoch: [1][260/750] Elapsed 1m 15s (remain 2m 21s) Loss: 0.1860(0.2702) Grad: 114703.4688  LR: 0.00001976  \n",
            "Epoch: [1][280/750] Elapsed 1m 20s (remain 2m 15s) Loss: 0.2003(0.2668) Grad: 118812.6641  LR: 0.00001972  \n",
            "Epoch: [1][300/750] Elapsed 1m 26s (remain 2m 9s) Loss: 0.3632(0.2613) Grad: 171774.5156  LR: 0.00001968  \n",
            "Epoch: [1][320/750] Elapsed 1m 32s (remain 2m 3s) Loss: 0.0039(0.2540) Grad: 16552.9395  LR: 0.00001964  \n",
            "Epoch: [1][340/750] Elapsed 1m 38s (remain 1m 57s) Loss: 0.1714(0.2485) Grad: 109254.9453  LR: 0.00001959  \n",
            "Epoch: [1][360/750] Elapsed 1m 44s (remain 1m 52s) Loss: 0.1269(0.2434) Grad: 92848.1406  LR: 0.00001955  \n",
            "Epoch: [1][380/750] Elapsed 1m 49s (remain 1m 46s) Loss: 0.2807(0.2427) Grad: 126603.9375  LR: 0.00001949  \n",
            "Epoch: [1][400/750] Elapsed 1m 55s (remain 1m 40s) Loss: 0.0604(0.2391) Grad: 74061.3516  LR: 0.00001944  \n",
            "Epoch: [1][420/750] Elapsed 2m 1s (remain 1m 34s) Loss: 0.1119(0.2395) Grad: 80010.6016  LR: 0.00001938  \n",
            "Epoch: [1][440/750] Elapsed 2m 6s (remain 1m 28s) Loss: 0.1196(0.2376) Grad: 76025.4062  LR: 0.00001933  \n",
            "Epoch: [1][460/750] Elapsed 2m 12s (remain 1m 23s) Loss: 0.1716(0.2336) Grad: 98437.5000  LR: 0.00001926  \n",
            "Epoch: [1][480/750] Elapsed 2m 18s (remain 1m 17s) Loss: 0.1173(0.2297) Grad: 105989.6797  LR: 0.00001920  \n",
            "Epoch: [1][500/750] Elapsed 2m 23s (remain 1m 11s) Loss: 0.4171(0.2302) Grad: 172529.7500  LR: 0.00001913  \n",
            "Epoch: [1][520/750] Elapsed 2m 29s (remain 1m 5s) Loss: 0.1917(0.2276) Grad: 104367.7578  LR: 0.00001906  \n",
            "Epoch: [1][540/750] Elapsed 2m 35s (remain 0m 59s) Loss: 0.1084(0.2246) Grad: 85700.1094  LR: 0.00001899  \n",
            "Epoch: [1][560/750] Elapsed 2m 41s (remain 0m 54s) Loss: 0.0805(0.2209) Grad: 63560.2773  LR: 0.00001892  \n",
            "Epoch: [1][580/750] Elapsed 2m 47s (remain 0m 48s) Loss: 0.0143(0.2186) Grad: 26500.0508  LR: 0.00001884  \n",
            "Epoch: [1][600/750] Elapsed 2m 52s (remain 0m 42s) Loss: 0.1661(0.2161) Grad: 103779.7031  LR: 0.00001876  \n",
            "Epoch: [1][620/750] Elapsed 2m 58s (remain 0m 37s) Loss: 0.0523(0.2141) Grad: 55587.9570  LR: 0.00001868  \n",
            "Epoch: [1][640/750] Elapsed 3m 4s (remain 0m 31s) Loss: 0.0720(0.2106) Grad: 64613.3008  LR: 0.00001859  \n",
            "Epoch: [1][660/750] Elapsed 3m 9s (remain 0m 25s) Loss: 1.1257(0.2090) Grad: 203364.1094  LR: 0.00001851  \n",
            "Epoch: [1][680/750] Elapsed 3m 15s (remain 0m 19s) Loss: 0.1302(0.2074) Grad: 88041.9297  LR: 0.00001842  \n",
            "Epoch: [1][700/750] Elapsed 3m 21s (remain 0m 14s) Loss: 0.1042(0.2041) Grad: 79858.2656  LR: 0.00001832  \n",
            "Epoch: [1][720/750] Elapsed 3m 26s (remain 0m 8s) Loss: 0.1794(0.2040) Grad: 112317.4766  LR: 0.00001823  \n",
            "Epoch: [1][740/750] Elapsed 3m 33s (remain 0m 2s) Loss: 0.0676(0.2031) Grad: 60480.6484  LR: 0.00001813  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d35ddcac0c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-48527d1f63f5>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-362f1fa430a6>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m#optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                \"of them.\")\n\u001b[1;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;34m\"none of output has requires_grad=True,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \" this checkpoint() is not necessary\")\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_with_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         grads = tuple(inp.grad if isinstance(inp, torch.Tensor) else None\n\u001b[1;32m    148\u001b[0m                       for inp in detached_inputs)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                \"of them.\")\n\u001b[1;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0minputGrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_backward_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputGrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36msoftmax_backward_data\u001b[0;34m(parent, grad_output, output, dim, self)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_softmax_backward_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_softmax_backward_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 604.00 MiB (GPU 0; 39.59 GiB total capacity; 36.19 GiB already allocated; 222.19 MiB free; 37.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07daa080",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-31T22:32:41.984286Z",
          "iopub.status.busy": "2022-08-31T22:32:41.983961Z",
          "iopub.status.idle": "2022-09-01T01:51:42.378681Z",
          "shell.execute_reply": "2022-09-01T01:51:42.377687Z"
        },
        "papermill": {
          "duration": 11940.406964,
          "end_time": "2022-09-01T01:51:42.380833",
          "exception": false,
          "start_time": "2022-08-31T22:32:41.973869",
          "status": "completed"
        },
        "tags": [],
        "id": "07daa080"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    \n",
        "    def get_result(oof_df):\n",
        "        labels = oof_df[CFG.target_cols].values\n",
        "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
        "        score, scores = get_score(labels, preds)\n",
        "        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
        "    \n",
        "    if CFG.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(CFG.n_fold):\n",
        "            if fold in CFG.trn_fold:\n",
        "                _oof_df = train_loop(train, fold)\n",
        "                oof_df = pd.concat([oof_df, _oof_df])\n",
        "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "                get_result(_oof_df)\n",
        "        oof_df = oof_df.reset_index(drop=True)\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
        "        \n",
        "    if CFG.wandb:\n",
        "        wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12032.949787,
      "end_time": "2022-09-01T01:51:45.270554",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-31T22:31:12.320767",
      "version": "2.3.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bffe53251994c9ca153202549dd5852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0203391c176486e8048d44856a830de",
              "IPY_MODEL_235e946c72034a83b29b138306dc2d1c",
              "IPY_MODEL_0888665440984b9a8f6bcb71ad7bae12"
            ],
            "layout": "IPY_MODEL_88cea0eccd7d46c69481218a8f22ac3d"
          }
        },
        "e0203391c176486e8048d44856a830de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e621c5ebcbf848e8a7d4b0fa8da0371d",
            "placeholder": "​",
            "style": "IPY_MODEL_41c28c954af14d9a9375ae74a81e4216",
            "value": "100%"
          }
        },
        "235e946c72034a83b29b138306dc2d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b087ad208e43b2af30ada54f9a7171",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd73281739dc4d3fbf1ecff719028cd4",
            "value": 1000
          }
        },
        "0888665440984b9a8f6bcb71ad7bae12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6658d500599423e967cff396a18c9df",
            "placeholder": "​",
            "style": "IPY_MODEL_17eb52cf493b479e8a747e98ee116d80",
            "value": " 1000/1000 [00:01&lt;00:00, 969.15it/s]"
          }
        },
        "88cea0eccd7d46c69481218a8f22ac3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e621c5ebcbf848e8a7d4b0fa8da0371d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c28c954af14d9a9375ae74a81e4216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b087ad208e43b2af30ada54f9a7171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd73281739dc4d3fbf1ecff719028cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6658d500599423e967cff396a18c9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17eb52cf493b479e8a747e98ee116d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}